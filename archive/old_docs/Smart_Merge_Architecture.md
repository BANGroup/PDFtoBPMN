# üèóÔ∏è –ê–†–•–ò–¢–ï–ö–¢–£–†–ê SMART MERGE –î–õ–Ø DEEPSEEK-OCR

**–î–∞—Ç–∞:** 31.10.2025  
**–ó–∞–¥–∞—á–∞:** –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ç –ø—Ä–æ–º–ø—Ç–æ–≤ `ocr_simple` –∏ `parse_figure` –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è BPMN

---

## üìã –í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï

### –í—Ö–æ–¥ A: –†–µ–∑—É–ª—å—Ç–∞—Ç `ocr_simple`
```python
{
  "raw_output": """
    <|ref|>npoecc2<|/ref|><|det|>[[595, 350, 649, 370]]<|/det|>
    <|ref|>C6bITHe1<|/ref|><|det|>[[500, 380, 560, 400]]<|/det|>
    <|ref|>npoecc1<|/ref|><|det|>[[355, 410, 409, 431]]<|/det|>
    <|ref|>npoecc3<|/ref|><|det|>[[595, 479, 649, 499]]<|/det|>
    <|ref|>C6bITHe2<|/ref|><|det|>[[500, 510, 560, 530]]<|/det|>
  """,
  "blocks": []  # –ü—É—Å—Ç–æ, —Ç–∞–∫ –∫–∞–∫ –ø–∞—Ä—Å–µ—Ä –Ω–µ –ø–æ–Ω–∏–º–∞–µ—Ç –∏—Å–∫–∞–∂–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
}
```

**–ß—Ç–æ –∏–º–µ–µ–º:**
- ‚úÖ –¢–æ—á–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ (bbox)
- ‚ö†Ô∏è –ò—Å–∫–∞–∂–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (latin —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è cyrillic)
- ‚ùå –ù–µ—Ç —Ç–∏–ø–æ–≤ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
- ‚ùå –ù–µ—Ç —Å–≤—è–∑–µ–π –º–µ–∂–¥—É —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏

### –í—Ö–æ–¥ B: –†–µ–∑—É–ª—å—Ç–∞—Ç `parse_figure`
```python
{
  "raw_output": """
    The main body of the document contains a diagram with three 
    interconnected boxes, each labeled "–ü—Ä–æ—Ü–µ—Å—Å 1," "–ü—Ä–æ—Ü–µ—Å—Å 2," 
    and "–ü—Ä–æ—Ü–µ—Å—Å 3," respectively. These boxes are connected by 
    arrows, indicating a flow or sequence of processes. The diagram 
    is labeled "–°–æ–±—ã—Ç–∏–µ 1," "–°–æ–±—ã—Ç–∏–µ 2," and "–°–æ–±—ã—Ç–∏–µ 3," which 
    translates to "Event 1," "Event 2," and "Event 3," respectively. 
    The boxes and arrows are colored in yellow, with the exception 
    of the "–°–æ–±—ã—Ç–∏–µ 1" box, which is in black.
  """,
  "blocks": []  # –ü—É—Å—Ç–æ, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ —Ä–µ–∂–∏–º describe
}
```

**–ß—Ç–æ –∏–º–µ–µ–º:**
- ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤ ("–ü—Ä–æ—Ü–µ—Å—Å 1", "–°–æ–±—ã—Ç–∏–µ 1")
- ‚úÖ –û–ø–∏—Å–∞–Ω–∏–µ —Å–≤—è–∑–µ–π ("connected by arrows")
- ‚úÖ –¢–∏–ø—ã —ç–ª–µ–º–µ–Ω—Ç–æ–≤ ("boxes" = Task, –º–æ–∂–µ—Ç –±—ã—Ç—å "circles" = Event)
- ‚úÖ –í–∏–∑—É–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (—Ü–≤–µ—Ç–∞)
- ‚ùå –ù–ï–¢ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç

---

## üéØ –¢–†–ï–ë–£–ï–ú–´–ô –í–´–•–û–î

```python
{
  "elements": [
    {
      "id": "element_1",
      "type": "bpmn:Task",           # –û–ø—Ä–µ–¥–µ–ª–µ–Ω –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è "boxes"
      "name": "–ü—Ä–æ—Ü–µ—Å—Å 1",           # –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–º—è –∏–∑ parse_figure
      "bbox": [355, 410, 409, 431],  # –¢–æ—á–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏–∑ ocr_simple
      "visual": {
        "color": "yellow",
        "shape": "box"
      }
    },
    {
      "id": "element_2",
      "type": "bpmn:Event",           # –û–ø—Ä–µ–¥–µ–ª–µ–Ω –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è –∏–ª–∏ —Ü–≤–µ—Ç–∞
      "name": "–°–æ–±—ã—Ç–∏–µ 1",
      "bbox": [500, 380, 560, 400],
      "visual": {
        "color": "black",
        "shape": "circle"
      }
    },
    # ...
  ],
  "connections": [
    {
      "id": "flow_1",
      "type": "bpmn:SequenceFlow",
      "source": "element_1",
      "target": "element_2"
    },
    # ...
  ]
}
```

---

## üß© –ö–û–ú–ü–û–ù–ï–ù–¢–´ –°–ò–°–¢–ï–ú–´

### 1. TextNormalizer
**–ó–∞–¥–∞—á–∞:** –ò—Å–ø—Ä–∞–≤–∏—Ç—å –∏—Å–∫–∞–∂–µ–Ω–Ω—É—é –∫–∏—Ä–∏–ª–ª–∏—Ü—É –∏–∑ `ocr_simple`

```python
class TextNormalizer:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏—Å–∫–∞–∂–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä—É—Å—Å–∫–∏–π.
    
    –ú–µ—Ç–æ–¥—ã:
    - cyrillic_from_latin_mangled() - –æ–±—Ä–∞—Ç–Ω–∞—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è
    - fuzzy_match() - –Ω–µ—á–µ—Ç–∫–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–∞–º–∏
    """
    
    TRANSLITERATION_MAP = {
        'n': '–ø',
        'p': '—Ä',
        'o': '–æ',
        'e': '–µ',
        'c': '—Å',
        'C': '–°',
        'b': '—ã',
        'I': '–ò',
        'T': '–¢',
        'H': '–ù',
        'e': '–µ',
        # ... –ø–æ–ª–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
    }
    
    def normalize(self, mangled_text: str) -> List[str]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏.
        
        –ü—Ä–∏–º–µ—Ä:
        "npoecc1" ‚Üí ["–ø—Ä–æ—Ü–µ—Å—Å1", "–ü—Ä–æ—Ü–µ—Å—Å 1", "–ø—Ä–æ—Ü–µ—Å—Å 1"]
        "C6bITHe1" ‚Üí ["—Å–æ–±—ã—Ç–∏–µ1", "–°–æ–±—ã—Ç–∏–µ 1", "—Å–æ–±—ã—Ç–∏–µ 1"]
        """
        # 1. –ü—Ä—è–º–∞—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è
        direct = self._apply_transliteration(mangled_text)
        
        # 2. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤ –ø–µ—Ä–µ–¥ —Ü–∏—Ñ—Ä–∞–º–∏
        spaced = self._add_spaces_before_digits(direct)
        
        # 3. –ö–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è
        variants = [
            spaced,
            spaced.lower(),
            spaced.capitalize(),
            spaced.title()
        ]
        
        return variants
```

**–ü—Ä–∏–Ω—Ü–∏–ø—ã:**
- **KISS:** –ü—Ä–æ—Å—Ç–∞—è —Ç–∞–±–ª–∏—Ü–∞ –∑–∞–º–µ–Ω—ã —Å–∏–º–≤–æ–ª–æ–≤
- **DRY:** –ï–¥–∏–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –≤—Å–µ—Ö –∏—Å–∫–∞–∂–µ–Ω–∏–π
- **SOLID (S):** –¢–æ–ª—å–∫–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞, –Ω–∏—á–µ–≥–æ –±–æ–ª—å—à–µ

---

### 2. LabelExtractor
**–ó–∞–¥–∞—á–∞:** –ò–∑–≤–ª–µ—á—å —Å–ø–∏—Å–æ–∫ –º–µ—Ç–æ–∫ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è `parse_figure`

```python
class LabelExtractor:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç regex + NLP –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –≤–∏–¥–∞:
    - "labeled '–ü—Ä–æ—Ü–µ—Å—Å 1'"
    - "each labeled 'X', 'Y', and 'Z'"
    - "'–°–æ–±—ã—Ç–∏–µ 1' ('Event 1')"
    """
    
    def extract_labels(self, description: str) -> List[dict]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏.
        
        –ü—Ä–∏–º–µ—Ä:
        [
          {"text": "–ü—Ä–æ—Ü–µ—Å—Å 1", "type_hint": "box", "color": "yellow"},
          {"text": "–ü—Ä–æ—Ü–µ—Å—Å 2", "type_hint": "box", "color": "yellow"},
          {"text": "–°–æ–±—ã—Ç–∏–µ 1", "type_hint": "circle", "color": "black"},
          ...
        ]
        """
        labels = []
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω 1: "labeled 'X', 'Y', and 'Z'"
        pattern1 = r"labeled \"([^\"]+)\""
        matches1 = re.findall(pattern1, description)
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω 2: "'X' ('Y')" - —Ä—É—Å—Å–∫–æ–µ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–µ
        pattern2 = r"\"([^\"]+)\"\s*\(\"([^\"]+)\"\)"
        matches2 = re.findall(pattern2, description)
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω 3: –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        # "boxes labeled X" ‚Üí X —ç—Ç–æ Task
        # "circles representing Y" ‚Üí Y —ç—Ç–æ Event
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        type_hints = self._extract_type_hints(description)
        color_info = self._extract_color_info(description)
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
        for label_text in all_matches:
            labels.append({
                "text": label_text,
                "type_hint": type_hints.get(label_text),
                "color": color_info.get(label_text),
                "context": self._get_context(description, label_text)
            })
        
        return labels
    
    def _extract_type_hints(self, description: str) -> dict:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ —ç–ª–µ–º–µ–Ω—Ç–æ–≤.
        
        –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞:
        - "boxes", "rectangles" ‚Üí Task
        - "circles", "ovals" ‚Üí Event
        - "diamonds", "gateway" ‚Üí Gateway
        - "arrows", "connected" ‚Üí SequenceFlow
        """
        type_map = {}
        
        # –ù–∞–π—Ç–∏ –≤—Å–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å —Ç–∏–ø–∞–º–∏
        # "three interconnected boxes, each labeled 'A', 'B', 'C'"
        # ‚Üí A, B, C = Task
        
        return type_map
```

**–ü—Ä–∏–Ω—Ü–∏–ø—ã:**
- **SOLID (S):** –¢–æ–ª—å–∫–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–æ–∫, –Ω–µ –ø–∞—Ä—Å–∏–Ω–≥ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
- **KISS:** –ü—Ä–æ—Å—Ç—ã–µ regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã
- **DRY:** –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã

---

### 3. CoordinateParser
**–ó–∞–¥–∞—á–∞:** –†–∞—Å–ø–∞—Ä—Å–∏—Ç—å `<|ref|>...<|det|>[[x,y,x,y]]<|/det|>` –∏–∑ `ocr_simple`

```python
class CoordinateParser:
    """
    –ü–∞—Ä—Å–∏—Ç raw output –æ—Ç ocr_simple –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —ç–ª–µ–º–µ–Ω—Ç—ã —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏.
    """
    
    def parse(self, raw_output: str) -> List[dict]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏.
        
        –ü—Ä–∏–º–µ—Ä:
        [
          {"text": "npoecc1", "bbox": [355, 410, 409, 431]},
          {"text": "C6bITHe1", "bbox": [500, 380, 560, 400]},
          ...
        ]
        """
        elements = []
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω: <|ref|>TEXT<|/ref|><|det|>[[x1,y1,x2,y2]]<|/det|>
        pattern = r'<\|ref\|>([^<]+)<\|/ref\|><\|det\|>\[\[([^\]]+)\]\]<\|/det\|>'
        
        for match in re.finditer(pattern, raw_output):
            text = match.group(1)
            coords_str = match.group(2)
            
            # –ü–∞—Ä—Å–∏–Ω–≥ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
            coords = [float(x.strip()) for x in coords_str.split(',')]
            
            if len(coords) == 4:
                elements.append({
                    "text": text,
                    "bbox": coords,
                    "bbox_dict": {
                        "x0": coords[0],
                        "y0": coords[1],
                        "x1": coords[2],
                        "y1": coords[3]
                    }
                })
        
        return elements
```

**–ü—Ä–∏–Ω—Ü–∏–ø—ã:**
- **SOLID (S):** –¢–æ–ª—å–∫–æ –ø–∞—Ä—Å–∏–Ω–≥, –Ω–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
- **KISS:** –ü—Ä—è–º–æ–π regex, –±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö FSM
- **DRY:** –û–¥–∏–Ω –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –≤—Å–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤

---

### 4. ElementMatcher (üî• –Ø–î–†–û –°–ò–°–¢–ï–ú–´)
**–ó–∞–¥–∞—á–∞:** –°–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å —ç–ª–µ–º–µ–Ω—Ç—ã –∏–∑ –¥–≤—É—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤

```python
class ElementMatcher:
    """
    –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∏—Å–∫–∞–∂–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ (ocr_simple) 
    —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ (parse_figure).
    
    –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ matching:
    1. Fuzzy string matching (Levenshtein distance)
    2. Semantic matching (–ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)
    3. Positional matching (–ø–æ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–º—É —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—é)
    4. Count matching (–µ—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–≤–ø–∞–¥–∞–µ—Ç)
    """
    
    def __init__(self, normalizer: TextNormalizer):
        self.normalizer = normalizer
    
    def match(
        self, 
        coord_elements: List[dict],  # –ò–∑ ocr_simple
        label_elements: List[dict]   # –ò–∑ parse_figure
    ) -> List[dict]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤.
        
        –ê–ª–≥–æ—Ä–∏—Ç–º:
        1. –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –∏—Å–∫–∞–∂–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –Ω–∞–π—Ç–∏ –ª—É—á—à–∏–π match –ø–æ –º–µ—Ç–∫–µ
        3. –ï—Å–ª–∏ match –Ω–∞–π–¥–µ–Ω - –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
        4. –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω - –æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º
        """
        matched = []
        unmatched_coords = []
        unmatched_labels = list(label_elements)
        
        # –≠–¢–ê–ü 1: –ü—Ä—è–º–æ–π matching (–ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)
        for coord_elem in coord_elements:
            mangled = coord_elem['text']
            bbox = coord_elem['bbox']
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏—Å–∫–∞–∂–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            normalized_variants = self.normalizer.normalize(mangled)
            
            # –ò—â–µ–º –ª—É—á—à–∏–π match —Å—Ä–µ–¥–∏ –º–µ—Ç–æ–∫
            best_match = None
            best_score = 0
            
            for label_elem in unmatched_labels:
                label_text = label_elem['text']
                
                # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –∫–∞–∂–¥—ã–º –≤–∞—Ä–∏–∞–Ω—Ç–æ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
                for variant in normalized_variants:
                    score = self._fuzzy_match_score(variant, label_text)
                    
                    if score > best_score:
                        best_score = score
                        best_match = label_elem
            
            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ö–æ—Ä–æ—à–∏–π match (score > 0.7)
            if best_score > 0.7 and best_match:
                matched.append({
                    "name": best_match['text'],           # –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–º—è
                    "bbox": bbox,                         # –¢–æ—á–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                    "type_hint": best_match.get('type_hint'),
                    "color": best_match.get('color'),
                    "confidence": best_score,
                    "original_text": mangled              # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
                })
                unmatched_labels.remove(best_match)
            else:
                unmatched_coords.append(coord_elem)
        
        # –≠–¢–ê–ü 2: Positional matching –¥–ª—è –Ω–µ—Å–ø–∞—Ä–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        if unmatched_coords and unmatched_labels:
            # –ï—Å–ª–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å–æ–≤–ø–∞–¥–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            if len(unmatched_coords) == len(unmatched_labels):
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±–∞ —Å–ø–∏—Å–∫–∞ –ø–æ Y-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–µ (—Å–≤–µ—Ä—Ö—É –≤–Ω–∏–∑)
                sorted_coords = sorted(
                    unmatched_coords, 
                    key=lambda x: x['bbox'][1]  # y0
                )
                sorted_labels = sorted(
                    unmatched_labels,
                    key=lambda x: self._infer_position(x, label_elements)
                )
                
                # –°–ø–∞—Ä–∏–≤–∞–µ–º –ø–æ –ø–æ—Ä—è–¥–∫—É
                for coord, label in zip(sorted_coords, sorted_labels):
                    matched.append({
                        "name": label['text'],
                        "bbox": coord['bbox'],
                        "type_hint": label.get('type_hint'),
                        "color": label.get('color'),
                        "confidence": 0.5,  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                        "matching_method": "positional",
                        "original_text": coord['text']
                    })
                
                unmatched_coords = []
                unmatched_labels = []
        
        # –≠–¢–ê–ü 3: –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏
        for coord in unmatched_coords:
            matched.append({
                "name": f"UNKNOWN_{coord['text']}",
                "bbox": coord['bbox'],
                "confidence": 0.1,
                "warning": "No matching label found",
                "original_text": coord['text']
            })
        
        return matched
    
    def _fuzzy_match_score(self, str1: str, str2: str) -> float:
        """
        –í—ã—á–∏—Å–ª—è–µ—Ç similarity score –º–µ–∂–¥—É —Å—Ç—Ä–æ–∫–∞–º–∏.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
        - Levenshtein distance
        - Normalized similarity (0.0 - 1.0)
        """
        from difflib import SequenceMatcher
        return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()
    
    def _infer_position(self, label: dict, all_labels: List[dict]) -> float:
        """
        –ü—ã—Ç–∞–µ—Ç—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—É—é –ø–æ–∑–∏—Ü–∏—é –º–µ—Ç–∫–∏
        –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø–∏—Å–∞–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞ –≤ parse_figure.
        
        –ü—Ä–∏–º–µ—Ä: "–ü—Ä–æ—Ü–µ—Å—Å 1" ‚Üí 1, "–ü—Ä–æ—Ü–µ—Å—Å 2" ‚Üí 2, "–ü—Ä–æ—Ü–µ—Å—Å 3" ‚Üí 3
        """
        text = label['text']
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞
        numbers = re.findall(r'\d+', text)
        if numbers:
            return float(numbers[0])
        
        # –ò–ª–∏ –ø–æ –ø–æ—Ä—è–¥–∫—É —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
        if 'context' in label:
            # –ê–Ω–∞–ª–∏–∑ –ø–æ–∑–∏—Ü–∏–∏ –≤ —Ç–µ–∫—Å—Ç–µ –æ–ø–∏—Å–∞–Ω–∏—è
            pass
        
        return 0.0
```

**–ü—Ä–∏–Ω—Ü–∏–ø—ã:**
- **SOLID (S):** –¢–æ–ª—å–∫–æ matching, –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
- **SOLID (O):** –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ matching –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–¥–∞
- **SOLID (D):** –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏ TextNormalizer
- **KISS:** –ü—Ä–æ—Å—Ç—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏, –Ω–µ ML
- **DRY:** –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

---

### 5. ConnectionExtractor
**–ó–∞–¥–∞—á–∞:** –ò–∑–≤–ª–µ—á—å —Å–≤—è–∑–∏ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è `parse_figure`

```python
class ConnectionExtractor:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–≤—è–∑—è—Ö –º–µ–∂–¥—É —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è.
    
    –ö–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã:
    - "connected by arrows"
    - "flow from X to Y"
    - "interconnected boxes"
    - "sequence of processes"
    """
    
    def extract_connections(
        self, 
        description: str,
        elements: List[dict]
    ) -> List[dict]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–≤—è–∑–µ–π.
        
        –ê–ª–≥–æ—Ä–∏—Ç–º:
        1. –ù–∞–π—Ç–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Å–≤—è–∑–µ–π ("connected", "arrows", "flow")
        2. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ (if specified)
        3. –ï—Å–ª–∏ —è–≤–Ω–æ–≥–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –Ω–µ—Ç - –≤—ã–≤–µ—Å—Ç–∏ –ø–æ –≥–µ–æ–º–µ—Ç—Ä–∏–∏ (—Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ, —Å–≤–µ—Ä—Ö—É –≤–Ω–∏–∑)
        """
        connections = []
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç —è–≤–Ω—ã—Ö —Å–≤—è–∑–µ–π
        # "A connected to B by arrow" ‚Üí A ‚Üí B
        explicit_connections = self._extract_explicit_connections(description)
        
        if explicit_connections:
            return explicit_connections
        
        # –ï—Å–ª–∏ —è–≤–Ω—ã—Ö —Å–≤—è–∑–µ–π –Ω–µ—Ç, –¥–µ–ª–∞–µ–º –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
        # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π flow —Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ
        if "sequence" in description.lower() or "flow" in description.lower():
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ X-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–µ
            sorted_elements = sorted(elements, key=lambda e: e['bbox'][0])
            
            # –°–æ–∑–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ —Å–≤—è–∑–∏
            for i in range(len(sorted_elements) - 1):
                connections.append({
                    "type": "bpmn:SequenceFlow",
                    "source": sorted_elements[i]['name'],
                    "target": sorted_elements[i + 1]['name'],
                    "confidence": 0.6,
                    "inferred": True
                })
        
        return connections
    
    def _extract_explicit_connections(self, description: str) -> List[dict]:
        """
        –ò—â–µ—Ç —è–≤–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è —Å–≤—è–∑–µ–π –≤ —Ç–µ–∫—Å—Ç–µ.
        
        –ü–∞—Ç—Ç–µ—Ä–Ω—ã:
        - "'X' connected to 'Y'"
        - "'X' flows to 'Y'"
        - "from 'X' to 'Y'"
        """
        connections = []
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω: "from X to Y"
        pattern = r"from\s+['\"]([^'\"]+)['\"]\s+to\s+['\"]([^'\"]+)['\"]"
        matches = re.findall(pattern, description, re.IGNORECASE)
        
        for source, target in matches:
            connections.append({
                "type": "bpmn:SequenceFlow",
                "source": source,
                "target": target,
                "confidence": 0.9,
                "inferred": False
            })
        
        return connections
```

**–ü—Ä–∏–Ω—Ü–∏–ø—ã:**
- **SOLID (S):** –¢–æ–ª—å–∫–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–≤—è–∑–µ–π
- **KISS:** –ü—Ä–æ—Å—Ç—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏ –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
- **DRY:** –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã

---

### 6. TypeInferencer
**–ó–∞–¥–∞—á–∞:** –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø BPMN —ç–ª–µ–º–µ–Ω—Ç–∞

```python
class TypeInferencer:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø BPMN —ç–ª–µ–º–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ:
    - type_hint –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è ("box", "circle", "diamond")
    - –ù–∞–∑–≤–∞–Ω–∏—è —ç–ª–µ–º–µ–Ω—Ç–∞ ("–ü—Ä–æ—Ü–µ—Å—Å" ‚Üí Task, "–°–æ–±—ã—Ç–∏–µ" ‚Üí Event)
    - –í–∏–∑—É–∞–ª—å–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ (—Ü–≤–µ—Ç, —Ñ–æ—Ä–º–∞)
    - –ì–µ–æ–º–µ—Ç—Ä–∏–∏ bbox (aspect ratio)
    """
    
    TYPE_KEYWORDS = {
        "bpmn:Task": ["–ø—Ä–æ—Ü–µ—Å—Å", "–∑–∞–¥–∞—á–∞", "–¥–µ–π—Å—Ç–≤–∏–µ", "–æ–ø–µ—Ä–∞—Ü–∏—è"],
        "bpmn:Event": ["—Å–æ–±—ã—Ç–∏–µ", "—Å—Ç–∞—Ä—Ç", "–∫–æ–Ω–µ—Ü", "–Ω–∞—á–∞–ª–æ"],
        "bpmn:Gateway": ["—à–ª—é–∑", "—É—Å–ª–æ–≤–∏–µ", "—Ä–∞–∑–≤–∏–ª–∫–∞", "gateway"]
    }
    
    TYPE_SHAPES = {
        "bpmn:Task": ["box", "rectangle"],
        "bpmn:Event": ["circle", "oval"],
        "bpmn:Gateway": ["diamond", "rhombus"]
    }
    
    def infer_type(self, element: dict) -> str:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–∏–ø BPMN —ç–ª–µ–º–µ–Ω—Ç–∞.
        
        –ê–ª–≥–æ—Ä–∏—Ç–º (–ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É):
        1. –ï—Å–ª–∏ –µ—Å—Ç—å type_hint –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ
        2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
        3. –ê–Ω–∞–ª–∏–∑ –≥–µ–æ–º–µ—Ç—Ä–∏–∏ bbox (—Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω)
        4. Default: Task
        """
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1: type_hint
        if 'type_hint' in element and element['type_hint']:
            hint = element['type_hint'].lower()
            for bpmn_type, shapes in self.TYPE_SHAPES.items():
                if hint in shapes:
                    return bpmn_type
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 2: –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
        name = element.get('name', '').lower()
        for bpmn_type, keywords in self.TYPE_KEYWORDS.items():
            for keyword in keywords:
                if keyword in name:
                    return bpmn_type
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 3: –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
        bbox = element.get('bbox')
        if bbox:
            width = bbox[2] - bbox[0]
            height = bbox[3] - bbox[1]
            aspect_ratio = width / height if height > 0 else 1.0
            
            # –ö—Ä—É–≥–∏ –∏–º–µ—é—Ç aspect_ratio ‚âà 1.0
            if 0.8 < aspect_ratio < 1.2:
                return "bpmn:Event"
            
            # –†–æ–º–±—ã (Gateway) —Ç–æ–∂–µ ‚âà 1.0, –Ω–æ –º–µ–Ω—å—à–µ –ø–æ —Ä–∞–∑–º–µ—Ä—É
            if 0.8 < aspect_ratio < 1.2 and width < 40:
                return "bpmn:Gateway"
        
        # Default
        return "bpmn:Task"
```

**–ü—Ä–∏–Ω—Ü–∏–ø—ã:**
- **SOLID (S):** –¢–æ–ª—å–∫–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞
- **SOLID (O):** –õ–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
- **KISS:** –ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –±–µ–∑ ML

---

### 7. BPMNHybridExtractor (–ì–õ–ê–í–ù–´–ô –û–†–ö–ï–°–¢–†–ê–¢–û–†)
**–ó–∞–¥–∞—á–∞:** –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤ –µ–¥–∏–Ω—ã–π pipeline

```python
class BPMNHybridExtractor:
    """
    –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è BPMN –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    
    Pipeline:
    1. –ó–∞–ø—Ä–æ—Å –∫ OCR —Å –ø—Ä–æ–º–ø—Ç–æ–º "ocr_simple" ‚Üí –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
    2. –ó–∞–ø—Ä–æ—Å –∫ OCR —Å –ø—Ä–æ–º–ø—Ç–æ–º "parse_figure" ‚Üí –º–µ—Ç–∫–∏ –∏ —Å–≤—è–∑–∏
    3. –ü–∞—Ä—Å–∏–Ω–≥ –æ–±–æ–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    4. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å–∫–∞–∂–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    5. Matching —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    6. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–≤—è–∑–µ–π
    7. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤
    8. –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ BPMN IR
    """
    
    def __init__(self, ocr_service_url: str):
        self.ocr_url = ocr_service_url
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.coord_parser = CoordinateParser()
        self.label_extractor = LabelExtractor()
        self.normalizer = TextNormalizer()
        self.matcher = ElementMatcher(self.normalizer)
        self.connection_extractor = ConnectionExtractor()
        self.type_inferencer = TypeInferencer()
    
    def extract(self, image_path: str) -> dict:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è BPMN.
        
        Returns: BPMN Intermediate Representation
        """
        logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ BPMN –∏–∑ {image_path}")
        
        # –®–ê–ì 1: OCR —Å ocr_simple (–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã)
        logger.info("  [1/7] –ó–∞–ø—Ä–æ—Å ocr_simple...")
        coord_result = self._ocr_request(image_path, "ocr_simple")
        coord_elements = self.coord_parser.parse(coord_result['raw_output'])
        logger.info(f"  –ù–∞–π–¥–µ–Ω–æ {len(coord_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏")
        
        # –®–ê–ì 2: OCR —Å parse_figure (–º–µ—Ç–∫–∏ –∏ —Å–≤—è–∑–∏)
        logger.info("  [2/7] –ó–∞–ø—Ä–æ—Å parse_figure...")
        label_result = self._ocr_request(image_path, "parse_figure")
        label_elements = self.label_extractor.extract_labels(
            label_result['raw_output']
        )
        logger.info(f"  –ù–∞–π–¥–µ–Ω–æ {len(label_elements)} –º–µ—Ç–æ–∫")
        
        # –®–ê–ì 3: Matching
        logger.info("  [3/7] Matching —ç–ª–µ–º–µ–Ω—Ç–æ–≤...")
        matched_elements = self.matcher.match(coord_elements, label_elements)
        logger.info(f"  –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ {len(matched_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
        
        # –®–ê–ì 4: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤
        logger.info("  [4/7] –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —ç–ª–µ–º–µ–Ω—Ç–æ–≤...")
        for elem in matched_elements:
            elem['type'] = self.type_inferencer.infer_type(elem)
        
        # –®–ê–ì 5: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–≤—è–∑–µ–π
        logger.info("  [5/7] –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–≤—è–∑–µ–π...")
        connections = self.connection_extractor.extract_connections(
            label_result['raw_output'],
            matched_elements
        )
        logger.info(f"  –ù–∞–π–¥–µ–Ω–æ {len(connections)} —Å–≤—è–∑–µ–π")
        
        # –®–ê–ì 6: –ü—Ä–∏—Å–≤–æ–µ–Ω–∏–µ ID
        logger.info("  [6/7] –ü—Ä–∏—Å–≤–æ–µ–Ω–∏–µ ID...")
        for i, elem in enumerate(matched_elements):
            elem['id'] = f"element_{i+1}"
        
        for i, conn in enumerate(connections):
            conn['id'] = f"flow_{i+1}"
        
        # –®–ê–ì 7: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ IR
        logger.info("  [7/7] –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ BPMN IR...")
        bpmn_ir = {
            "elements": matched_elements,
            "connections": connections,
            "metadata": {
                "source_image": image_path,
                "extraction_method": "hybrid_deepseek_ocr",
                "timestamp": datetime.now().isoformat(),
                "ocr_simple_elements": len(coord_elements),
                "parse_figure_labels": len(label_elements),
                "matched_elements": len(matched_elements),
                "confidence_avg": self._calc_avg_confidence(matched_elements)
            }
        }
        
        logger.info("‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        return bpmn_ir
    
    def _ocr_request(self, image_path: str, prompt_type: str) -> dict:
        """–ó–∞–ø—Ä–æ—Å –∫ OCR —Å–µ—Ä–≤–∏—Å—É"""
        with open(image_path, 'rb') as f:
            files = {"file": f}
            data = {"prompt_type": prompt_type}
            response = requests.post(
                f"{self.ocr_url}/ocr/figure",
                files=files,
                data=data,
                timeout=120
            )
            response.raise_for_status()
            return response.json()
    
    def _calc_avg_confidence(self, elements: List[dict]) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å—Ä–µ–¥–Ω—é—é —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å matching"""
        confidences = [e.get('confidence', 0.0) for e in elements]
        return sum(confidences) / len(confidences) if confidences else 0.0
```

**–ü—Ä–∏–Ω—Ü–∏–ø—ã:**
- **SOLID (S):** –û—Ä–∫–µ—Å—Ç—Ä–∏—Ä—É–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã, –Ω–µ –¥–µ–ª–∞–µ—Ç –∏—Ö —Ä–∞–±–æ—Ç—É
- **SOLID (D):** –ó–∞–≤–∏—Å–∏—Ç –æ—Ç –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
- **KISS:** –õ–∏–Ω–µ–π–Ω—ã–π pipeline –±–µ–∑ —Å–ª–æ–∂–Ω–æ–π –ª–æ–≥–∏–∫–∏
- **DRY:** –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

---

## üìä –ü–†–ò–ú–ï–† –†–ê–ë–û–¢–´

### –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:

**–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ:** page_54_bpmn.png

### –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:

**–ü–æ—Å–ª–µ CoordinateParser:**
```python
[
  {"text": "npoecc1", "bbox": [355, 410, 409, 431]},
  {"text": "C6bITHe1", "bbox": [500, 380, 560, 400]},
  {"text": "npoecc2", "bbox": [595, 350, 649, 370]},
  {"text": "npoecc3", "bbox": [595, 479, 649, 499]},
  {"text": "C6bITHe2", "bbox": [500, 510, 560, 530]},
]
```

**–ü–æ—Å–ª–µ LabelExtractor:**
```python
[
  {"text": "–ü—Ä–æ—Ü–µ—Å—Å 1", "type_hint": "box", "color": "yellow"},
  {"text": "–ü—Ä–æ—Ü–µ—Å—Å 2", "type_hint": "box", "color": "yellow"},
  {"text": "–ü—Ä–æ—Ü–µ—Å—Å 3", "type_hint": "box", "color": "yellow"},
  {"text": "–°–æ–±—ã—Ç–∏–µ 1", "type_hint": "circle", "color": "black"},
  {"text": "–°–æ–±—ã—Ç–∏–µ 2", "type_hint": "circle", "color": "yellow"},
]
```

**–ü–æ—Å–ª–µ TextNormalizer (–¥–ª—è "npoecc1"):**
```python
[
  "–ø—Ä–æ—Ü–µ—Å—Å1",
  "–ü—Ä–æ—Ü–µ—Å—Å 1",
  "–ø—Ä–æ—Ü–µ—Å—Å 1",
  "–ü–†–û–¶–ï–°–° 1"
]
```

**–ü–æ—Å–ª–µ ElementMatcher:**
```python
[
  {
    "name": "–ü—Ä–æ—Ü–µ—Å—Å 1",
    "bbox": [355, 410, 409, 431],
    "type_hint": "box",
    "color": "yellow",
    "confidence": 0.95,
    "original_text": "npoecc1"
  },
  {
    "name": "–°–æ–±—ã—Ç–∏–µ 1",
    "bbox": [500, 380, 560, 400],
    "type_hint": "circle",
    "color": "black",
    "confidence": 0.92,
    "original_text": "C6bITHe1"
  },
  # ...
]
```

**–ü–æ—Å–ª–µ TypeInferencer:**
```python
[
  {
    "id": "element_1",
    "type": "bpmn:Task",
    "name": "–ü—Ä–æ—Ü–µ—Å—Å 1",
    "bbox": [355, 410, 409, 431],
    # ...
  },
  {
    "id": "element_2",
    "type": "bpmn:Event",
    "name": "–°–æ–±—ã—Ç–∏–µ 1",
    "bbox": [500, 380, 560, 400],
    # ...
  },
  # ...
]
```

**–ü–æ—Å–ª–µ ConnectionExtractor:**
```python
[
  {
    "id": "flow_1",
    "type": "bpmn:SequenceFlow",
    "source": "element_1",
    "target": "element_2",
    "confidence": 0.6
  },
  # ...
]
```

### –§–∏–Ω–∞–ª—å–Ω—ã–π BPMN IR:

```json
{
  "elements": [
    {
      "id": "element_1",
      "type": "bpmn:Task",
      "name": "–ü—Ä–æ—Ü–µ—Å—Å 1",
      "bbox": [355, 410, 409, 431],
      "visual": {"color": "yellow", "shape": "box"},
      "confidence": 0.95
    },
    {
      "id": "element_2",
      "type": "bpmn:Event",
      "name": "–°–æ–±—ã—Ç–∏–µ 1",
      "bbox": [500, 380, 560, 400],
      "visual": {"color": "black", "shape": "circle"},
      "confidence": 0.92
    }
  ],
  "connections": [
    {
      "id": "flow_1",
      "type": "bpmn:SequenceFlow",
      "source": "element_1",
      "target": "element_2"
    }
  ],
  "metadata": {
    "extraction_method": "hybrid_deepseek_ocr",
    "confidence_avg": 0.89
  }
}
```

---

## ‚öñÔ∏è –û–¶–ï–ù–ö–ê –¢–û–ß–ù–û–°–¢–ò

### –°—Ü–µ–Ω–∞—Ä–∏–π 1: –ò–¥–µ–∞–ª—å–Ω—ã–π match
- –ò—Å–∫–∞–∂–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Ö–æ—Ä–æ—à–æ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç—Å—è
- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å–æ–≤–ø–∞–¥–∞–µ—Ç
- **–¢–æ—á–Ω–æ—Å—Ç—å:** 90-95%

### –°—Ü–µ–Ω–∞—Ä–∏–π 2: –ß–∞—Å—Ç–∏—á–Ω—ã–π match
- –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–µ —É–¥–∞–µ—Ç—Å—è –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è positional matching
- **–¢–æ—á–Ω–æ—Å—Ç—å:** 70-80%

### –°—Ü–µ–Ω–∞—Ä–∏–π 3: –°–ª–æ–∂–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞
- –ú–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤, –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è
- –ù–µ—á–µ—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–≤—è–∑–µ–π
- **–¢–æ—á–Ω–æ—Å—Ç—å:** 60-70%

---

## üöÄ –ü–†–ï–ò–ú–£–©–ï–°–¢–í–ê –ü–û–î–•–û–î–ê

1. ‚úÖ **–†–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ fine-tuning**
2. ‚úÖ **–ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –æ–±–æ–∏—Ö –ø—Ä–æ–º–ø—Ç–æ–≤**
3. ‚úÖ **–ü—Ä–æ–∑—Ä–∞—á–Ω—ã–π –∏ –æ—Ç–ª–∞–∂–∏–≤–∞–µ–º—ã–π** (–∫–∞–∂–¥—ã–π —à–∞–≥ —è–≤–Ω—ã–π)
4. ‚úÖ **–†–∞—Å—à–∏—Ä—è–µ–º—ã–π** (–ª–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏)
5. ‚úÖ **Fault-tolerant** (fallback –Ω–∞ positional matching)

---

## ‚ö†Ô∏è –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø

1. ‚è±Ô∏è **–î–≤–æ–π–Ω–æ–µ –≤—Ä–µ–º—è** (~19 —Å–µ–∫ –≤–º–µ—Å—Ç–æ 9 —Å–µ–∫)
2. üéØ **–ù–µ 100% —Ç–æ—á–Ω–æ—Å—Ç—å** (–æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –¥–∏–∞–≥—Ä–∞–º–º)
3. üîß **–¢—Ä–µ–±—É–µ—Ç —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏** —ç–≤—Ä–∏—Å—Ç–∏–∫ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ BPMN
4. ‚ö†Ô∏è **–ú–æ–∂–µ—Ç –æ—à–∏–±–∞—Ç—å—Å—è –≤ —Å–≤—è–∑—è—Ö** (–µ—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è)

---

## üìà –í–û–ó–ú–û–ñ–ù–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø

### –§–∞–∑–∞ 2 (–µ—Å–ª–∏ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è):
1. **ML –¥–ª—è matching:** –û–±—É—á–∏—Ç—å –Ω–µ–±–æ–ª—å—à—É—é –º–æ–¥–µ–ª—å –Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö –∏—Å–∫–∞–∂–µ–Ω–∏–π
2. **Computer Vision –¥–ª—è —Å–≤—è–∑–µ–π:** –î–µ—Ç–µ–∫—Ü–∏—è —Å—Ç—Ä–µ–ª–æ–∫ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
3. **LLM –¥–ª—è post-processing:** GPT-4 –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
4. **Feedback loop:** –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ—à–∏–±–∫–∞—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π

---

## üéØ –ò–¢–û–ì

**Smart merge - —ç—Ç–æ:**
- 7 —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
- 2 –∑–∞–ø—Ä–æ—Å–∞ –∫ OCR —Å–µ—Ä–≤–∏—Å—É
- 5 —ç—Ç–∞–ø–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
- –ú–Ω–æ–∂–µ—Å—Ç–≤–æ —ç–≤—Ä–∏—Å—Ç–∏–∫ –∏ fallback-—Å—Ç—Ä–∞—Ç–µ–≥–∏–π
- –ü—Ä–æ–∑—Ä–∞—á–Ω—ã–π –∏ —Ä–∞—Å—à–∏—Ä—è–µ–º—ã–π pipeline

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- BPMN IR —Å —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏, —Å–≤—è–∑—è–º–∏ –∏ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏
- –ì–æ—Ç–æ–≤ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –≤ BPMN XML
- Confidence scores –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏


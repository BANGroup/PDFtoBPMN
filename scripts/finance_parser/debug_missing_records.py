"""
–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π - –ø–æ—á–µ–º—É –Ω–µ –≤—Å–µ –∏–∑–≤–ª–µ–∫–∞—é—Ç—Å—è
"""

import pandas as pd
from pathlib import Path
import re

def analyze_missing():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∫–∏–µ –∑–∞–ø–∏—Å–∏ –ø—Ä–æ–ø—É—â–µ–Ω—ã"""
    
    # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª—ã
    old_df = pd.read_excel("output/finance/–í—ã–ø—É—Å–∫_4-02_–Ω–∞_16.06.2020.xlsx")
    new_df = pd.read_excel("output/finance_marker/–í—ã–ø—É—Å–∫_4-02_marker.xlsx")
    md_path = Path("output/finance_marker/–í—ã–ø—É—Å–∫ 4-02 –Ω–∞ 16.06.2020/–í—ã–ø—É—Å–∫ 4-02 –Ω–∞ 16.06.2020.md")
    
    print("="*80)
    print("üîç –ê–ù–ê–õ–ò–ó –ü–†–û–ü–£–©–ï–ù–ù–´–• –ó–ê–ü–ò–°–ï–ô")
    print("="*80)
    print()
    
    # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∏–º–µ–Ω–∞
    old_names = set(old_df['–§–ò–û'].dropna().values)
    new_names = set(new_df['–§–ò–û'].dropna().values)
    missing_names = old_names - new_names
    
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –°—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: {len(old_names)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–º–µ–Ω")
    print(f"   –ù–æ–≤—ã–π —Ñ–∞–π–ª:  {len(new_names)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–º–µ–Ω")
    print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ:   {len(missing_names)} –∏–º–µ–Ω")
    print()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 10 –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö
    print("="*80)
    print("‚ùå –ü–†–ò–ú–ï–†–´ –ü–†–û–ü–£–©–ï–ù–ù–´–• –ó–ê–ü–ò–°–ï–ô")
    print("="*80)
    print()
    
    with open(md_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    for i, name in enumerate(list(missing_names)[:10], 1):
        print(f"{i}. {name}")
        
        # –ò—â–µ–º —ç—Ç–æ –∏–º—è –≤ Markdown
        if name in content:
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ –∏–º–µ–Ω–∏
            pos = content.find(name)
            context_start = max(0, pos - 300)
            context_end = min(len(content), pos + 300)
            context = content[context_start:context_end]
            
            print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ –≤ MD (–ø–æ–∑–∏—Ü–∏—è {pos})")
            
            # –ò—â–µ–º –∫–æ–¥ –≤–ª–∞–¥–µ–ª—å—Ü–∞ —Ä—è–¥–æ–º
            code_pattern = r'(01_\d+)'
            codes_nearby = re.findall(code_pattern, context)
            if codes_nearby:
                print(f"   –ö–æ–¥—ã —Ä—è–¥–æ–º: {codes_nearby}")
            else:
                print(f"   ‚ö†Ô∏è –ö–æ–¥ –≤–ª–∞–¥–µ–ª—å—Ü–∞ –ù–ï –Ω–∞–π–¥–µ–Ω —Ä—è–¥–æ–º!")
            
            # –ò—â–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä—è–¥–æ–º
            qty_pattern = r'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ —à—Ç—É–∫–∞—Ö[^\d]*?(\d+)'
            qty_match = re.search(qty_pattern, context)
            if qty_match:
                print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {qty_match.group(1)}")
            else:
                print(f"   ‚ö†Ô∏è –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ù–ï –Ω–∞–π–¥–µ–Ω–æ!")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç
            print(f"\n   –§—Ä–∞–≥–º–µ–Ω—Ç MD:")
            print(f"   {'‚îÄ'*76}")
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º 3 —Å—Ç—Ä–æ–∫–∏ –≤–æ–∫—Ä—É–≥ –∏–º–µ–Ω–∏
            lines = context.split('\n')
            name_line_idx = None
            for idx, line in enumerate(lines):
                if name in line:
                    name_line_idx = idx
                    break
            
            if name_line_idx:
                start = max(0, name_line_idx - 2)
                end = min(len(lines), name_line_idx + 3)
                for line in lines[start:end]:
                    preview = line[:74]
                    print(f"   {preview}")
            print()
        else:
            print(f"   ‚ùå –ù–ï –Ω–∞–π–¥–µ–Ω–æ –≤ MD!")
            print()
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–∫–æ–ª—å–∫–æ –∫–æ–¥–æ–≤ –≤–ª–∞–¥–µ–ª—å—Ü–∞ –≤ MD
    print("="*80)
    print("üìã –ü–û–î–°–ß–ï–¢ –ö–û–î–û–í –í–õ–ê–î–ï–õ–¨–¶–ê")
    print("="*80)
    print()
    
    code_pattern = r'–ö–æ–¥, –ø—Ä–∏—Å–≤–æ–µ–Ω–Ω—ã–π –Ω–æ–º–∏–Ω–∞–ª—å–Ω—ã–º –¥–µ—Ä–∂–∞—Ç–µ–ª–µ–º[^\|]*\|(01_\d+)'
    all_codes = re.findall(code_pattern, content)
    
    print(f"–ù–∞–π–¥–µ–Ω–æ –∫–æ–¥–æ–≤ '–ö–æ–¥, –ø—Ä–∏—Å–≤–æ–µ–Ω–Ω—ã–π –Ω–æ–º–∏–Ω–∞–ª—å–Ω—ã–º...': {len(all_codes)}")
    
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫ - –ø—Ä–æ—Å—Ç–æ –≤—Å–µ –∫–æ–¥—ã 01_XXXXXXXXXX
    simple_codes = re.findall(r'\b(01_\d{11})\b', content)
    print(f"–ù–∞–π–¥–µ–Ω–æ –∫–æ–¥–æ–≤ —Ñ–æ—Ä–º–∞—Ç–∞ 01_XXXXXXXXXXX: {len(set(simple_codes))}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ
    qty_all = re.findall(r'–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ —à—Ç—É–∫–∞—Ö', content, re.IGNORECASE)
    print(f"–ù–∞–π–¥–µ–Ω–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ —à—Ç—É–∫–∞—Ö': {len(qty_all)}")
    
    print()
    print("="*80)
    print("üí° –í–´–í–û–î")
    print("="*80)
    print()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ
    old_count = len(old_df)
    marker_count = len(new_df)
    codes_count = len(all_codes)
    
    print(f"–ó–∞–ø–∏—Å–µ–π –≤ —Å—Ç–∞—Ä–æ–º Excel:  {old_count}")
    print(f"–ö–æ–¥–æ–≤ –≤ Markdown:        {codes_count}")
    print(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ –ø–∞—Ä—Å–µ—Ä–æ–º:      {marker_count}")
    print()
    
    if codes_count > marker_count:
        print(f"‚ö†Ô∏è –ü–∞—Ä—Å–µ—Ä –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç {codes_count - marker_count} –∑–∞–ø–∏—Å–µ–π!")
        print("   –ü—Ä–∏—á–∏–Ω–∞: –≤–æ–∑–º–æ–∂–Ω–æ –≤–∞–ª–∏–¥–∞—Ü–∏—è –≤ _parse_record() –æ—Ç–±—Ä–∞—Å—ã–≤–∞–µ—Ç –∑–∞–ø–∏—Å–∏")
        print("   –†–µ—à–µ–Ω–∏–µ: —Å–º—è–≥—á–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–ª–∏ –¥–æ–±–∞–≤–∏—Ç—å –æ—Ç–ª–∞–¥–∫—É")
    
    if old_count != codes_count:
        print(f"\n‚ö†Ô∏è –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–¥–æ–≤ –≤ MD ({codes_count}) != –∑–∞–ø–∏—Å–µ–π –≤ —Å—Ç–∞—Ä–æ–º Excel ({old_count})")
        print("   –í–æ–∑–º–æ–∂–Ω–æ –≤ —Å—Ç–∞—Ä–æ–º Excel –µ—Å—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –∏–ª–∏ –∑–∞–ø–∏—Å–∏ –±–µ–∑ –∫–æ–¥–æ–≤")


if __name__ == "__main__":
    analyze_missing()



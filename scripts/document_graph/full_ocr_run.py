#!/usr/bin/env python3
"""
–ü–æ–ª–Ω—ã–π –ø—Ä–æ–≥–æ–Ω OCR DeepSeek –¥–ª—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
–° –∑–∞—Å–µ—á–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
"""

import sys
import time
import json

# –û—Ç–∫–ª—é—á–∞–µ–º –±—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—é –¥–ª—è real-time –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
sys.stdout.reconfigure(line_buffering=True)
sys.stderr.reconfigure(line_buffering=True)
from pathlib import Path
from datetime import datetime, timedelta

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from scripts.pdf_to_context.pipeline import PDFToContextPipeline


def format_duration(seconds):
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    if seconds < 60:
        return f"{seconds:.1f} —Å–µ–∫"
    elif seconds < 3600:
        return f"{seconds/60:.1f} –º–∏–Ω"
    else:
        hours = int(seconds // 3600)
        mins = int((seconds % 3600) // 60)
        return f"{hours} —á {mins} –º–∏–Ω"


def main():
    start_time = time.time()
    start_datetime = datetime.now()
    
    print("=" * 70)
    print("üöÄ –ü–û–õ–ù–´–ô –ü–†–û–ì–û–ù OCR DeepSeek")
    print("=" * 70)
    print(f"‚è∞ –°—Ç–∞—Ä—Ç: {start_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # –ü—É—Ç–∏
    input_path = Path("/home/budnik_an/Obligations/input2/BND/pdf")
    output_base = Path("/home/budnik_an/Obligations/output/ocr_full_run")
    output_base.mkdir(parents=True, exist_ok=True)
    
    log_file = output_base / f"ocr_run_{start_datetime.strftime('%Y%m%d_%H%M%S')}.log"
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ PDF —Ñ–∞–π–ª—ã
    pdf_files = []
    for folder in input_path.iterdir():
        if folder.is_dir():
            for pdf in folder.glob("*.pdf"):
                if "–¥–ª—è –ø–µ—á–∞—Ç–∏" in pdf.name or "–¥–ª—è –æ–∑–Ω–∞–∫–æ–º–ª–µ–Ω–∏—è" in pdf.name:
                    pdf_files.append(pdf)
    
    total_files = len(pdf_files)
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ PDF —Ñ–∞–π–ª–æ–≤: {total_files}")
    print()
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = {
        "total": total_files,
        "success": 0,
        "failed": 0,
        "skipped": 0,
        "total_pages": 0,
        "total_time": 0,
        "files": []
    }
    
    # Pipeline —Å OCR
    pipeline = PDFToContextPipeline(
        enable_ocr=True,
        ocr_base_url="http://localhost:8000"
    )
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
    for idx, pdf_path in enumerate(pdf_files, 1):
        file_start = time.time()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –∏–º–µ–Ω–∏ –ø–∞–ø–∫–∏
        doc_code = pdf_path.parent.name.split(" ^")[0] if " ^" in pdf_path.parent.name else pdf_path.stem
        
        print(f"\n[{idx}/{total_files}] üìÑ {doc_code}")
        print(f"    –§–∞–π–ª: {pdf_path.name}")
        
        try:
            # –í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
            output_file = output_base / f"{doc_code}_OCR.md"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ª–∏ —É–∂–µ
            if output_file.exists():
                print(f"    ‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω (—É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)")
                stats["skipped"] += 1
                stats["files"].append({
                    "code": doc_code,
                    "status": "skipped",
                    "reason": "already exists"
                })
                continue
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ - process() –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç markdown —Å—Ç—Ä–æ–∫—É
            markdown_result = pipeline.process(str(pdf_path), output_path=str(output_file))
            
            if markdown_result:
                file_time = time.time() - file_start
                
                # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–∑ PDF
                import fitz
                with fitz.open(str(pdf_path)) as doc:
                    pages = len(doc)
                
                stats["success"] += 1
                stats["total_pages"] += pages
                stats["files"].append({
                    "code": doc_code,
                    "status": "success",
                    "pages": pages,
                    "time": file_time,
                    "output": str(output_file)
                })
                
                print(f"    ‚úÖ –£—Å–ø–µ—à–Ω–æ: {pages} —Å—Ç—Ä, {format_duration(file_time)}")
            else:
                raise Exception("–ü—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
                
        except Exception as e:
            file_time = time.time() - file_start
            stats["failed"] += 1
            stats["files"].append({
                "code": doc_code,
                "status": "failed",
                "error": str(e),
                "time": file_time
            })
            print(f"    ‚ùå –û—à–∏–±–∫–∞: {e}")
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å –∏ ETA
        elapsed = time.time() - start_time
        if idx > 0:
            avg_time = elapsed / idx
            remaining = (total_files - idx) * avg_time
            eta = datetime.now() + timedelta(seconds=remaining)
            print(f"    üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {idx}/{total_files} ({idx*100//total_files}%), ETA: {eta.strftime('%H:%M:%S')}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –ª–æ–≥
        if idx % 10 == 0:
            stats["elapsed_time"] = elapsed
            with open(log_file, "w", encoding="utf-8") as f:
                json.dump(stats, f, ensure_ascii=False, indent=2)
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_time = time.time() - start_time
    end_datetime = datetime.now()
    
    stats["total_time"] = total_time
    stats["end_time"] = end_datetime.isoformat()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –ª–æ–≥
    with open(log_file, "w", encoding="utf-8") as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)
    
    print()
    print("=" * 70)
    print("üèÅ –ó–ê–í–ï–†–®–ï–ù–û!")
    print("=" * 70)
    print(f"‚è∞ –ù–∞—á–∞–ª–æ:     {start_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"‚è∞ –ö–æ–Ω–µ—Ü:      {end_datetime.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {format_duration(total_time)}")
    print()
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ:  {stats['success']}")
    print(f"   ‚ùå –û—à–∏–±–∫–∏:   {stats['failed']}")
    print(f"   ‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: {stats['skipped']}")
    print(f"   üìÑ –°—Ç—Ä–∞–Ω–∏—Ü:  {stats['total_pages']}")
    print()
    if stats['success'] > 0:
        avg_per_file = total_time / stats['success']
        print(f"   ‚ö° –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —Ñ–∞–π–ª: {format_duration(avg_per_file)}")
        if stats['total_pages'] > 0:
            avg_per_page = total_time / stats['total_pages']
            print(f"   ‚ö° –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É: {format_duration(avg_per_page)}")
    print()
    print(f"üìù –õ–æ–≥: {log_file}")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {output_base}")
    

if __name__ == "__main__":
    main()

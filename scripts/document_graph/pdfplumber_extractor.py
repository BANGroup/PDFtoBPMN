"""
PDF —Ç–µ–∫—Å—Ç–æ–≤—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ pdfplumber.

pdfplumber –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å:
- –ü–æ—Ä—è–¥–∫–æ–º —Ç–µ–∫—Å—Ç–∞ (—Å–≤–µ—Ä—Ö—É –≤–Ω–∏–∑, —Å–ª–µ–≤–∞ –Ω–∞–ø—Ä–∞–≤–æ)
- –¢–∞–±–ª–∏—Ü–∞–º–∏ (–∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É)
- –ö–æ–ª–æ–Ω–∫–∞–º–∏

PyMuPDF –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å:
- –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
- –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —à—Ä–∏—Ñ—Ç–∞—Ö
- –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é

–ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥:
- –¢–∏—Ç—É–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞: OCR (—Ç–µ–∫—Å—Ç —Å –±–∏—Ç–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π)
- –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: pdfplumber (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫)
"""

import pdfplumber
import fitz  # PyMuPDF –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ —Ç–∏—Ç—É–ª—å–Ω–æ–π –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
import requests
import re
import ast
from pathlib import Path
from typing import List, Dict, Optional
from dataclasses import dataclass
from io import BytesIO

try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False

from scripts.pdf_to_context.extractors.ocr_client import OCRClient
from scripts.pdf_to_context.extractors.native_extractor import NativeExtractor


@dataclass
class PageContent:
    """–ö–æ–Ω—Ç–µ–Ω—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    page_num: int
    text: str
    tables: List[List[List[str]]]  # –°–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü, –∫–∞–∂–¥–∞—è —Ç–∞–±–ª–∏—Ü–∞ - —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫


def _has_header_footer_markers(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –º–∞—Ä–∫–µ—Ä–æ–≤ –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–∞ –≤ —Ç–µ–∫—Å—Ç–µ."""
    if not text:
        return False
    text_lower = text.lower()
    patterns = [
        r'—Å—Ç—Ä\.\s*\d+\s*–∏–∑\s*\d+',
        r'–¥–∞—Ç–∞ –≤–≤–µ–¥–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è',
        r'–æ—Å–Ω–æ–≤–∞–Ω–∏–µ',
    ]
    return any(re.search(p, text_lower) for p in patterns)


def _crop_header_footer(img: "Image.Image",
                        crop_top: bool,
                        crop_bottom: bool,
                        top_ratio: float = 0.08,
                        bottom_ratio: float = 0.08) -> "Image.Image":
    """–û–±—Ä–µ–∑–∞—Ç—å –≤–µ—Ä—Ö–Ω—é—é –∏/–∏–ª–∏ –Ω–∏–∂–Ω—é—é –ø–æ–ª–æ—Å—É –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–∞."""
    width, height = img.size
    top = int(height * top_ratio) if crop_top else 0
    bottom = int(height * (1 - bottom_ratio)) if crop_bottom else height
    if bottom <= top:
        return img
    return img.crop((0, top, width, bottom))


def _extract_version_from_ocr(lines: List[str]) -> Optional[str]:
    """
    –ò–∑–≤–ª–µ—á—å –≤–µ—Ä—Å–∏—é –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–ò–ó–î–ê–ù–ò–ï/–†–ï–í–ò–ó–ò–Ø) –∏–∑ OCR —Ç–µ–∫—Å—Ç–∞ —Ç–∏—Ç—É–ª—å–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã.
    
    –ü–∞—Ç—Ç–µ—Ä–Ω—ã:
    - "–ò–ó–î–ê–ù–ò–ï 2 / –†–ï–í–ò–ó–ò–Ø 0"
    - "–ò–ó–î–ê–ù–ò–ï 2/–†–ï–í–ò–ó–ò–Ø 0/–î–∞—Ç–∞ –≤–≤–µ–¥–µ–Ω–∏—è:"
    - "Issue/–ò–∑–¥–∞–Ω–∏–µ 3"
    - "Rev./–†–µ–≤–∏–∑–∏—è 1"
    
    Returns:
        –°—Ç—Ä–æ–∫–∞ —Å –≤–µ—Ä—Å–∏–µ–π –∏–ª–∏ None
    """
    full_text = " ".join(lines)
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω 1: –ò–ó–î–ê–ù–ò–ï N / –†–ï–í–ò–ó–ò–Ø M
    match = re.search(r'–ò–ó–î–ê–ù–ò–ï\s*(\d+)\s*/\s*–†–ï–í–ò–ó–ò–Ø\s*(\d+)', full_text, re.IGNORECASE)
    if match:
        return f"–ò–∑–¥–∞–Ω–∏–µ {match.group(1)}, –†–µ–≤–∏–∑–∏—è {match.group(2)}"
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω 2: Issue/–ò–∑–¥–∞–Ω–∏–µ N
    match = re.search(r'(?:Issue\s*/\s*)?–ò–∑–¥–∞–Ω–∏–µ\s+(\d+)', full_text, re.IGNORECASE)
    if match:
        edition = match.group(1)
        # –ò—â–µ–º —Ä–µ–≤–∏–∑–∏—é —Ä—è–¥–æ–º
        rev_match = re.search(r'(?:Rev\.?\s*/\s*)?–†–µ–≤–∏–∑–∏—è\s+(\d+)', full_text, re.IGNORECASE)
        revision = rev_match.group(1) if rev_match else "0"
        return f"–ò–∑–¥–∞–Ω–∏–µ {edition}, –†–µ–≤–∏–∑–∏—è {revision}"
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω 3: –í–µ—Ä—Å–∏—è N
    match = re.search(r'–í–µ—Ä—Å–∏—è\s+(\d+)', full_text, re.IGNORECASE)
    if match:
        return f"–í–µ—Ä—Å–∏—è {match.group(1)}"
    
    return None


def ocr_title_page(pdf_path: str | Path, 
                   ocr_url: str = "http://localhost:8000/ocr/figure",
                   timeout: int = 60,
                   scale: float = 2.0,
                   fallback_scale: float = 1.0,
                   prompt_type: str = "default",
                   qwen_service=None) -> Optional[str]:
    """
    –†–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–∏—Ç—É–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —á–µ—Ä–µ–∑ OCR.
    
    –¢–∏—Ç—É–ª—å–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —á–∞—Å—Ç–æ –∏–º–µ—é—Ç —Ç–µ–∫—Å—Ç —Å –±–∏—Ç–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π (–≤–µ–∫—Ç–æ—Ä –≥—Ä–∞—Ñ–∏–∫–∞),
    –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —á–∏—Ç–∞–µ—Ç—Å—è —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ –ø–∞—Ä—Å–µ—Ä–∞–º–∏.
    
    Args:
        pdf_path: –ü—É—Ç—å –∫ PDF
        ocr_url: URL OCR —Å–µ—Ä–≤–∏—Å–∞
        timeout: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞
        qwen_service: QwenVLService –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ VLM (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞–¥ HTTP)
    
    Returns:
        Markdown —Ç–µ–∫—Å—Ç —Ç–∏—Ç—É–ª—å–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if not PIL_AVAILABLE:
        return None
    
    doc = None
    try:
        doc = fitz.open(str(pdf_path))
        page = doc[0]
        raw_text = page.get_text() or ""
        
        def render_to_buffer(render_scale: float) -> BytesIO:
            mat = fitz.Matrix(render_scale, render_scale)
            pix = page.get_pixmap(matrix=mat)
            img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
            if _has_header_footer_markers(raw_text):
                img = _crop_header_footer(img, crop_top=True, crop_bottom=True)
            buffer = BytesIO()
            img.save(buffer, format="JPEG", quality=95)
            buffer.seek(0)
            return buffer
        
        def _format_title_result(text: str) -> Optional[str]:
            """–§–æ—Ä–º–∏—Ä—É–µ—Ç markdown –∏–∑ OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞."""
            lines = []
            for line in text.split('\n'):
                line = line.strip()
                if line and not line.startswith('BASE:') and not line.startswith('NO PATCHES'):
                    lines.append(line)
            if not lines:
                return None
            title_md = "# –¢–ò–¢–£–õ–¨–ù–ê–Ø –°–¢–†–ê–ù–ò–¶–ê\n\n"
            for line in lines:
                if line:
                    title_md += f"{line}\n\n"
            version_info = _extract_version_from_ocr(lines)
            if version_info:
                title_md += f"\n**–í–µ—Ä—Å–∏—è:** {version_info}\n\n"
            return title_md
        
        # –í–∞—Ä–∏–∞–Ω—Ç 1: Qwen VLM (–ª–æ–∫–∞–ª—å–Ω—ã–π, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        if qwen_service is not None:
            try:
                buffer = render_to_buffer(scale)
                image_bytes = buffer.read()
                ocr_text = qwen_service.process_image(
                    image_bytes,
                    "–ò–∑–≤–ª–µ–∫–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç —Å —Ç–∏—Ç—É–ª—å–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞. "
                    "–í–∫–ª—é—á–∏: –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏, –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞, –∫–æ–¥ –¥–æ–∫—É–º–µ–Ω—Ç–∞, "
                    "–Ω–æ–º–µ—Ä –∏–∑–¥–∞–Ω–∏—è, —Ä–µ–≤–∏–∑–∏—é, –¥–∞—Ç—É –≤–≤–µ–¥–µ–Ω–∏—è, –≥–æ—Ä–æ–¥, –≥–æ–¥. –§–æ—Ä–º–∞—Ç: Markdown."
                )
                if ocr_text:
                    result = _format_title_result(ocr_text)
                    if result:
                        return result
            except Exception as exc:
                print(f"Qwen VLM title OCR error: {exc}")
        
        # –í–∞—Ä–∏–∞–Ω—Ç 2: DeepSeek OCR HTTP
        def request_ocr_http(buffer: BytesIO) -> Optional[str]:
            response = requests.post(
                ocr_url,
                files={"file": ("title.jpg", buffer, "image/jpeg")},
                data={"prompt_type": prompt_type},
                timeout=timeout
            )
            if not response.ok:
                return None
            result = response.json()
            markdown = result.get("markdown", "")
            return _format_title_result(markdown)
        
        try:
            buffer = render_to_buffer(scale)
            title_md = request_ocr_http(buffer)
            if title_md:
                return title_md
        except Exception as exc:
            print(f"DeepSeek title OCR error (scale={scale}): {exc}")
        if fallback_scale and fallback_scale != scale:
            try:
                buffer = render_to_buffer(fallback_scale)
                title_md = request_ocr_http(buffer)
                if title_md:
                    return title_md
            except Exception as exc:
                print(f"DeepSeek title OCR error (scale={fallback_scale}): {exc}")
        return None
    except Exception as e:
        print(f"Title OCR error: {e}")
        return None
    finally:
        if doc is not None:
            try:
                doc.close()
            except Exception:
                pass


def is_title_page_corrupted(pdf_path: str | Path) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–º–µ–µ—Ç –ª–∏ —Ç–∏—Ç—É–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –±–∏—Ç—É—é –∫–æ–¥–∏—Ä–æ–≤–∫—É —Ç–µ–∫—Å—Ç–∞.
    
    –ü—Ä–∏–∑–Ω–∞–∫–∏:
    - –¢–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∞—Ç–∏–Ω—Å–∫–∏–µ –±—É–∫–≤—ã –≤–º–µ—Å—Ç–æ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
    - –®—Ä–∏—Ñ—Ç Helvetica —Å WinAnsiEncoding
    """
    try:
        doc = fitz.open(str(pdf_path))
        page = doc[0]
        text = page.get_text()[:500]
        doc.close()
        
        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –∫–æ—Ä–æ—Ç–∫–∏–π –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–Ω–æ–≥–æ –ª–∞—Ç–∏–Ω–∏—Ü—ã - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –±–∏—Ç–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞
        if len(text) < 50:
            return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ª–∞—Ç–∏–Ω–∏—Ü—ã –∫ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ
        import re
        latin = len(re.findall(r'[a-zA-Z]', text))
        cyrillic = len(re.findall(r'[–∞-—è–ê-–Ø—ë–Å]', text))
        
        # –ï—Å–ª–∏ –ª–∞—Ç–∏–Ω–∏—Ü—ã –±–æ–ª—å—à–µ 50% - –±–∏—Ç–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞
        if latin > (latin + cyrillic) * 0.5:
            return True
        
        return False
        
    except Exception:
        return False


def extract_text_pdfplumber(pdf_path: str | Path, 
                            skip_first_n_pages: int = 0,
                            ocr_title: bool = True,
                            ocr_url: str = "http://localhost:8000/ocr/figure",
                            ocr_graphics: bool = False,
                            ocr_base_url: str = "http://localhost:8000",
                            ocr_engine: str = "deepseek") -> str:
    """
    –ò–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ PDF –∏—Å–ø–æ–ª—å–∑—É—è pdfplumber.
    
    –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥:
    - –¢–∏—Ç—É–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞: OCR (–µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å –±–∏—Ç–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π)
    - –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: pdfplumber (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫)
    
    Args:
        pdf_path: –ü—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É
        skip_first_n_pages: –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å –ø–µ—Ä–≤—ã–µ N —Å—Ç—Ä–∞–Ω–∏—Ü (—Ç–∏—Ç—É–ª—å–Ω–∞—è –∏ —Ç.–¥.)
        ocr_title: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å OCR –¥–ª—è —Ç–∏—Ç—É–ª—å–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        ocr_url: URL OCR —Å–µ—Ä–≤–∏—Å–∞
    
    Returns:
        –¢–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ Markdown —Ñ–æ—Ä–º–∞—Ç–µ
    """
    markdown_parts = []
    pdf_path = Path(pdf_path)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–µ–Ω –ª–∏ OCR –¥–ª—è —Ç–∏—Ç—É–ª—å–Ω–æ–π
    use_ocr_for_title = ocr_title and is_title_page_corrupted(pdf_path)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OCR-–¥–≤–∏–∂–∫–∞
    ocr_client = None
    qwen_service = None
    if ocr_graphics:
        if ocr_engine == "qwen":
            # Qwen 2B VLM ‚Äî –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω–æ, –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞
            try:
                from scripts.pdf_to_context.ocr_service.qwen_service import QwenVLService
                qwen_service = QwenVLService(max_new_tokens=1024)
                if qwen_service.is_available():
                    print("   üß† OCR engine: Qwen2-VL-2B (–ª–æ–∫–∞–ª—å–Ω—ã–π VLM)")
                else:
                    qwen_service = None
                    print("   ‚ö†Ô∏è Qwen VL –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, fallback –Ω–∞ DeepSeek OCR")
            except Exception as e:
                print(f"   ‚ö†Ô∏è Qwen VL init error: {e}, fallback –Ω–∞ DeepSeek OCR")
                qwen_service = None
        
        if qwen_service is None:
            ocr_client = OCRClient(base_url=ocr_base_url, max_retries=1, timeout=30) if ocr_graphics else None
    
    native_extractor = NativeExtractor(
        extract_images=True,
        extract_drawings=True,
        extract_tables=False,
        render_vectors_to_image=bool(ocr_graphics),
        vector_render_dpi=300
    ) if ocr_graphics else None
    fitz_doc = fitz.open(str(pdf_path)) if ocr_graphics else None
    ocr_graphics_active = bool(ocr_graphics and (ocr_client or qwen_service) and native_extractor and fitz_doc)
    
    # LayoutDetector –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–ö–∞—Ç–µ–≥–æ—Ä–∏—è 3)
    layout_detector = None
    diagram_detector = None
    if ocr_graphics_active:
        try:
            from scripts.pdf_to_context.extractors.layout_detector import (
                get_layout_detector as _get_ld,
                is_layout_detection_available,
            )
            if is_layout_detection_available():
                layout_detector = _get_ld(confidence_threshold=0.25)
        except Exception:
            pass  # Graceful degradation
        
        # DiagramElementDetector (YOLO12) –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å—Ö–µ–º
        try:
            from scripts.pdf_to_context.extractors.layout_detector import (
                get_diagram_detector,
                is_diagram_detection_available,
                DiagramElementDetector as _DED,
            )
            if is_diagram_detection_available():
                diagram_detector = get_diagram_detector()
                if not diagram_detector.is_available():
                    diagram_detector = None
        except Exception:
            pass  # Graceful degradation: –±–µ–∑ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º OCR
    
    with pdfplumber.open(pdf_path) as pdf:
        for i, page in enumerate(pdf.pages):
            page_num = i + 1
            
            # –¢–∏—Ç—É–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å OCR
            if i == 0 and use_ocr_for_title:
                markdown_parts.append(f"\n<!-- –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} (OCR) -->\n")
                ocr_result = ocr_title_page(pdf_path, ocr_url, qwen_service=qwen_service)
                if ocr_result:
                    markdown_parts.append(ocr_result)
                else:
                    markdown_parts.append("<!-- OCR –Ω–µ —É–¥–∞–ª—Å—è -->\n")
                continue
            
            if i < skip_first_n_pages:
                markdown_parts.append(f"\n<!-- –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} (–ø—Ä–æ–ø—É—â–µ–Ω–∞) -->\n")
                continue
            
            markdown_parts.append(f"\n<!-- –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} -->\n")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã (–µ—Å–ª–∏ –µ—Å—Ç—å) –∏ –∏—Å–∫–ª—é—á–∞–µ–º –∏—Ö –∏–∑ —Ç–µ–∫—Å—Ç–∞
            found_tables = page.find_tables(table_settings={
                "vertical_strategy": "lines",
                "horizontal_strategy": "lines",
                "snap_tolerance": 3,
            })
            table_data_list = []  # [(data, bbox_top), ...]
            table_cells = set()
            table_rows = set()
            if found_tables:
                for tbl in found_tables:
                    data = tbl.extract()
                    if not data:
                        continue
                    # –í–∞–ª–∏–¥–∞—Ü–∏—è: –æ—Ç—Å–µ–∏–≤–∞–µ–º –ª–æ–∂–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã (–ö–∞—Ç–µ–≥–æ—Ä–∏—è 6)
                    if not _is_valid_table(data):
                        continue
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ merged cells: forward fill (–ö–∞—Ç–µ–≥–æ—Ä–∏—è 2)
                    data = _forward_fill_table(data)
                    tbl_top = tbl.bbox[1] if tbl.bbox else 0
                    table_data_list.append((data, tbl_top))
                    for row in data:
                        cells = []
                        for cell in row:
                            cell_norm = _normalize_text(_escape_cell(cell))
                            if cell_norm:
                                table_cells.add(cell_norm)
                                cells.append(cell_norm)
                        if cells:
                            table_rows.add(_normalize_text(" ".join(cells)))
            if found_tables:
                filtered_page = _filter_table_chars(page, found_tables)
                text = filtered_page.extract_text()
            else:
                text = page.extract_text()
            
            # –ò–Ω—Ç–µ—Ä–ª–∏–≤–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ –∏ —Ç–∞–±–ª–∏—Ü –ø–æ Y-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º (–ö–∞—Ç–µ–≥–æ—Ä–∏—è 1)
            if text:
                # –û—á–∏—Å—Ç–∫–∞ –æ—Ç –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–æ–≤
                lines = text.split('\n')
                cleaned_lines = []
                
                for line in lines:
                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª—ã
                    if _is_header_footer(line):
                        continue
                    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü (—Å—Ç—Ä–æ–∫–∏, —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ —Å —è—á–µ–π–∫–∞–º–∏)
                    if found_tables:
                        line_norm = _normalize_text(line)
                        if line_norm in table_cells or line_norm in table_rows:
                            continue
                        if len(line_norm) <= 120:
                            # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —è—á–µ–µ–∫, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–∞–º–∏
                            for row_text in table_rows:
                                if line_norm == row_text:
                                    break
                            else:
                                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç 2+ –∑–Ω–∞—á–µ–Ω–∏—è —è—á–µ–µ–∫
                                hits = 0
                                for cell in table_cells:
                                    if len(cell) < 4:
                                        continue
                                    if cell in line_norm:
                                        hits += 1
                                        if hits >= 2:
                                            break
                                if hits >= 2:
                                    continue
                                cleaned_lines.append(line)
                            continue
                    cleaned_lines.append(line)
                
                if table_data_list:
                    # –ò–Ω—Ç–µ—Ä–ª–∏–≤–∏–Ω–≥: –≤—Å—Ç–∞–≤–ª—è–µ–º —Ç–∞–±–ª–∏—Ü—ã –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ –ø–æ Y
                    _interleave_text_and_tables(
                        cleaned_lines, table_data_list, page, markdown_parts
                    )
                else:
                    # –ù–µ—Ç —Ç–∞–±–ª–∏—Ü ‚Äî –ø—Ä–æ—Å—Ç–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
                    for line in cleaned_lines:
                        formatted = _format_heading(line)
                        markdown_parts.append(formatted)
            elif table_data_list:
                # –ù–µ—Ç —Ç–µ–∫—Å—Ç–∞, –Ω–æ –µ—Å—Ç—å —Ç–∞–±–ª–∏—Ü—ã
                for data, _ in table_data_list:
                    if data:
                        markdown_parts.append(_table_to_markdown(data))

            # OCR –≥—Ä–∞—Ñ–∏–∫–∏ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è + –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ —Å—Ö–µ–º—ã) ‚Äî –ö–∞—Ç–µ–≥–æ—Ä–∏—è 3
            if ocr_graphics_active:
                fitz_page = fitz_doc[page_num - 1]
                ocr_chunks = []
                page_area = fitz_page.rect.width * fitz_page.rect.height
                figure_counter = 0
                
                # –ü–æ–ª—É—á–∞–µ–º layout-–∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –µ—Å–ª–∏ LayoutDetector –¥–æ—Å—Ç—É–ø–µ–Ω
                layout_elements = []
                if layout_detector:
                    try:
                        layout_elements = layout_detector.detect_from_page(fitz_page, dpi=150)
                    except Exception:
                        pass  # Graceful degradation
                
                # –ú–Ω–æ–∂–µ—Å—Ç–≤–æ bbox –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (header/footer) –æ—Ç LayoutDetector
                hf_bboxes = []
                for elem in layout_elements:
                    if elem.category.value in ("header", "footer", "page-number"):
                        hf_bboxes.append(elem.bbox)
                
                # –†–∞—Å—Ç—Ä–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ‚Äî –ø–æ—Ä–æ–≥ —Å–Ω–∏–∂–µ–Ω –¥–æ 0.02 (2%) —Å LayoutDetector
                min_area_ratio = 0.02 if layout_detector else 0.08
                for image_block in native_extractor.extract_image_blocks(fitz_page):
                    if image_block.bbox.area() / page_area < min_area_ratio:
                        continue
                    
                    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ LayoutDetector
                    if hf_bboxes and _bbox_overlaps_any(image_block.bbox, hf_bboxes):
                        continue
                    
                    figure_counter += 1
                    ocr_text = _process_image_ocr(
                        image_block.image_data, page_num, image_block.bbox,
                        qwen_service, ocr_client, figure_counter
                    )
                    if ocr_text:
                        ocr_chunks.append(ocr_text)
                
                # –í–µ–∫—Ç–æ—Ä–Ω—ã–µ —Å—Ö–µ–º—ã ‚Äî –ø–æ—Ä–æ–≥ —Å–Ω–∏–∂–µ–Ω –¥–æ 0.02 —Å LayoutDetector
                drawing_blocks = native_extractor.extract_drawing_blocks(
                    fitz_page,
                    render_to_image=False,
                    render_dpi=300
                )
                for drawing_block in drawing_blocks:
                    if drawing_block.bbox.area() / page_area < min_area_ratio:
                        continue
                    
                    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                    if hf_bboxes and _bbox_overlaps_any(drawing_block.bbox, hf_bboxes):
                        continue
                    
                    if not ocr_graphics_active:
                        break
                    image_bytes = native_extractor._render_region_to_image(
                        fitz_page,
                        drawing_block.bbox,
                        dpi=300
                    )
                    if not image_bytes:
                        continue
                    figure_counter += 1
                    ocr_text = _process_image_ocr(
                        image_bytes, page_num, drawing_block.bbox,
                        qwen_service, ocr_client, figure_counter
                    )
                    if ocr_text:
                        ocr_chunks.append(ocr_text)
                
                # –ï—Å–ª–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –µ—Å—Ç—å vector drawings –Ω–æ –Ω–∏ –æ–¥–∏–Ω –Ω–µ –ø–æ–ø–∞–ª –≤ OCR,
                # –∏ Qwen –¥–æ—Å—Ç—É–ø–µ–Ω ‚Äî —Ä–µ–Ω–¥–µ—Ä–∏–º –≤—Å—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ü–µ–ª–∏–∫–æ–º (–ø.10: –æ—Ä–≥—Å—Ç—Ä—É–∫—Ç—É—Ä—ã)
                if not ocr_chunks and qwen_service is not None and drawing_blocks:
                    # –ü–æ–¥—Å—á–∏—Ç–∞–µ–º –æ–±—â—É—é –ø–ª–æ—â–∞–¥—å drawings –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                    total_drawing_area = sum(
                        db.bbox.area() for db in drawing_blocks
                        if not (hf_bboxes and _bbox_overlaps_any(db.bbox, hf_bboxes))
                    )
                    if total_drawing_area / page_area > 0.15:
                        # –ó–Ω–∞—á–∏–º–∞—è —á–∞—Å—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—ã ‚Äî –≤–µ–∫—Ç–æ—Ä–Ω–∞—è –≥—Ä–∞—Ñ–∏–∫–∞
                        page_png = _render_page_to_png(fitz_page, dpi=200)
                        if page_png:
                            figure_counter += 1
                            ocr_text = _process_image_ocr(
                                page_png, page_num, None,
                                qwen_service, None, figure_counter
                            )
                            if ocr_text:
                                ocr_chunks.append(ocr_text)
                
                if ocr_chunks:
                    markdown_parts.append("\n".join(ocr_chunks))
    
    if fitz_doc:
        fitz_doc.close()
    
    # –í—ã–≥—Ä—É–∑–∏—Ç—å Qwen –∏–∑ GPU –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if qwen_service is not None:
        try:
            qwen_service.unload_model()
        except Exception:
            pass
    
    return '\n'.join(markdown_parts)


def extract_pages_pdfplumber(pdf_path: str | Path) -> List[PageContent]:
    """
    –ò–∑–≤–ª–µ—á—å –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ.
    
    Args:
        pdf_path: –ü—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É
    
    Returns:
        –°–ø–∏—Å–æ–∫ PageContent –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    """
    pages = []
    
    with pdfplumber.open(pdf_path) as pdf:
        for i, page in enumerate(pdf.pages):
            text = page.extract_text() or ""
            tables = page.extract_tables() or []
            
            pages.append(PageContent(
                page_num=i + 1,
                text=text,
                tables=tables
            ))
    
    return pages


def _is_header_footer(line: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–æ–º."""
    line_lower = line.strip().lower()
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–æ–≤
    patterns = [
        '—Å—Ç—Ä.',
        '–¥–∞—Ç–∞ –≤–≤–µ–¥–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏—è',
        '–¥–∞—Ç–∞ –≤–≤–µ–¥–µ–Ω–∏—è',
        '–æ—Å–Ω–æ–≤–∞–Ω–∏–µ',
        '___'
    ]
    
    # –ö–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ —Å –Ω–æ–º–µ—Ä–æ–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    if '–∏–∑' in line_lower and len(line.strip()) < 20:
        return True
    
    for p in patterns:
        if p in line_lower:
            return True
    
    return False


def _format_heading(line: str) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ."""
    import re
    
    line = line.strip()
    if not line:
        return '\n'
    
    # –ù—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏: 1, 1.1, 1.1.1, etc.
    # –ü–∞—Ç—Ç–µ—Ä–Ω: –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —Ü–∏—Ñ—Ä—ã, –º–æ–∂–µ—Ç –±—ã—Ç—å —Ç–æ—á–∫–∏ –∏ —Ü–∏—Ñ—Ä—ã, –ó–ê–¢–ï–ú —Ç–µ–∫—Å—Ç —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã
    # –ò—Å–∫–ª—é—á–∞–µ–º: "9001 ¬´–°–∏—Å—Ç–µ–º—ã..." - —ç—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    heading_match = re.match(r'^(\d+(?:\.\d+)*)\s+([–ê-–ØA-Z].+)$', line)
    if heading_match:
        num = heading_match.group(1)
        title = heading_match.group(2)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–º (–Ω–µ —Ü–µ–ª–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)
        # –∏ –Ω–µ –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å–æ —Å—Ç—Ä–æ—á–Ω–æ–π –±—É–∫–≤—ã –≤ –∫–∞–≤—ã—á–∫–∞—Ö
        if title.startswith('¬´') or len(title) > 150:
            return line + '\n'
        
        level = num.count('.') + 1
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –∑–∞–≥–æ–ª–æ–≤–∫–∞ markdown
        if level == 1:
            return f'# {num} {title}\n'
        elif level == 2:
            return f'## {num} {title}\n'
        elif level == 3:
            return f'### {num} {title}\n'
        else:
            return f'#### {num} {title}\n'
    
    # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –∫–∞–ø—Å–æ–º (–ü–†–ï–î–ò–°–õ–û–í–ò–ï, –°–û–î–ï–†–ñ–ê–ù–ò–ï –∏ —Ç.–¥.)
    # –ù–æ –Ω–µ —Å–ª–æ–≤–∞ —Ç–∏–ø–∞ "ISO", "IATA" –∏ —Ç.–¥. (–∫–æ—Ä–æ—Ç–∫–∏–µ)
    if line.isupper() and len(line) > 5 and len(line) < 80:
        # –ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ü–∏—Ñ—Ä –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ (–ì–û–°–¢ 9001 - –Ω–µ –∑–∞–≥–æ–ª–æ–≤–æ–∫)
        if not re.search(r'\d', line):
            return f'# {line}\n'
    
    return line + '\n'


def _escape_cell(cell: Optional[str]) -> str:
    """–≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —è—á–µ–π–∫–∏ –¥–ª—è Markdown-—Ç–∞–±–ª–∏—Ü—ã."""
    if cell is None:
        return ' '
    cell_str = str(cell)
    # –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ Markdown
    cell_str = cell_str.replace('|', '\\|')
    # –£–±–∏—Ä–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫ –≤–Ω—É—Ç—Ä–∏ —è—á–µ–µ–∫
    cell_str = cell_str.replace('\n', ' ').replace('\r', ' ')
    cell_str = cell_str.strip()
    return cell_str if cell_str else ' '


def _normalize_text(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø—Ä–æ–±–µ–ª—ã –≤ —Å—Ç—Ä–æ–∫–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."""
    text = text.replace('\u00A0', ' ').replace('\u202F', ' ').replace('\u2009', ' ')
    return re.sub(r'\s+', ' ', text).strip()


def _has_cyrillic(text: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã –≤ —Ç–µ–∫—Å—Ç–µ."""
    return re.search(r'[–∞-—è–ê-–Ø—ë–Å]', text) is not None


def _ocr_markdown_to_text(ocr_markdown: str) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å OCR markdown —Å —Ç–µ–≥–∞–º–∏ ref/det –≤ —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç."""
    if not ocr_markdown:
        return ""
    # –£–±–∏—Ä–∞–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
    cleaned = []
    for line in ocr_markdown.splitlines():
        line = line.strip()
        if not line:
            continue
        if line.startswith("BASE:") or line.startswith("NO PATCHES"):
            continue
        cleaned.append(line)
    ocr_markdown = "\n".join(cleaned)
    matches = re.findall(r'<\|ref\|>(.*?)<\|/ref\|>', ocr_markdown)
    if matches:
        return "\n".join(m.strip() for m in matches if m.strip())
    return ocr_markdown.strip()


def _ocr_markdown_to_lines(ocr_markdown: str) -> list[str]:
    """–°–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å OCR —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ —Å—Ç—Ä–æ–∫–∞–º –Ω–∞ –æ—Å–Ω–æ–≤–µ bbox."""
    if not ocr_markdown:
        return []
    pattern = r'<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>'
    items = []
    for text, det in re.findall(pattern, ocr_markdown):
        try:
            bbox_list = ast.literal_eval(det)
            if not bbox_list:
                continue
            x0, y0, x1, y1 = bbox_list[0]
            items.append({
                "text": text.strip(),
                "x0": float(x0),
                "y0": float(y0),
                "y1": float(y1),
            })
        except Exception:
            continue
    if not items:
        return []
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º
    items.sort(key=lambda i: (i["y0"], i["x0"]))
    lines = []
    current = []
    current_y = None
    threshold = 18.0
    for item in items:
        y_center = (item["y0"] + item["y1"]) / 2
        if current_y is None or abs(y_center - current_y) <= threshold:
            current.append(item)
            current_y = y_center if current_y is None else (current_y + y_center) / 2
        else:
            current.sort(key=lambda i: i["x0"])
            line_text = " ".join(i["text"] for i in current if i["text"])
            if line_text:
                lines.append(line_text)
            current = [item]
            current_y = y_center
    if current:
        current.sort(key=lambda i: i["x0"])
        line_text = " ".join(i["text"] for i in current if i["text"])
        if line_text:
            lines.append(line_text)
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏
    seen = set()
    unique_lines = []
    for line in lines:
        norm = _normalize_text(line)
        if norm and norm not in seen:
            seen.add(norm)
            unique_lines.append(line)
    return unique_lines


def _ocr_markdown_to_boxes(ocr_markdown: str) -> list[dict]:
    """–°–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å OCR —ç–ª–µ–º–µ–Ω—Ç—ã –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –±–ª–æ–∫–∏ (–±–æ–∫—Å—ã)."""
    if not ocr_markdown:
        return []
    pattern = r'<\|ref\|>(.*?)<\|/ref\|><\|det\|>(.*?)<\|/det\|>'
    tokens = []
    for text, det in re.findall(pattern, ocr_markdown):
        text = text.strip()
        if len(text) < 2:
            continue
        if not _has_cyrillic(text) and not re.search(r'[A-Z–ê-–Ø]{2,}', text):
            continue
        try:
            bbox_list = ast.literal_eval(det)
            if not bbox_list:
                continue
            x0, y0, x1, y1 = bbox_list[0]
            tokens.append({
                "text": text,
                "x0": float(x0),
                "y0": float(y0),
                "x1": float(x1),
                "y1": float(y1),
            })
        except Exception:
            continue
    if not tokens:
        return []

    # 1) –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫–∏
    tokens.sort(key=lambda t: (t["y0"], t["x0"]))
    lines = []
    current = []
    current_y = None
    line_threshold = 14.0
    for t in tokens:
        y_center = (t["y0"] + t["y1"]) / 2
        if current_y is None or abs(y_center - current_y) <= line_threshold:
            current.append(t)
            current_y = y_center if current_y is None else (current_y + y_center) / 2
        else:
            current.sort(key=lambda i: i["x0"])
            lines.extend(_split_line_segments(current))
            current = [t]
            current_y = y_center
    if current:
        current.sort(key=lambda i: i["x0"])
        lines.extend(_split_line_segments(current))

    # 2) –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ –≤ –±–æ–∫—Å—ã –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏ –∏ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—é –ø–æ X
    boxes = []
    lines.sort(key=lambda l: (l["y0"], l["x0"]))
    box = None
    for line in lines:
        if not box:
            box = {
                "lines": [line["text"]],
                "x0": line["x0"],
                "x1": line["x1"],
                "y0": line["y0"],
                "y1": line["y1"],
            }
            continue
        vertical_gap = line["y0"] - box["y1"]
        x_overlap = max(0.0, min(box["x1"], line["x1"]) - max(box["x0"], line["x0"]))
        overlap_ratio = x_overlap / max(1.0, min(box["x1"] - box["x0"], line["x1"] - line["x0"]))
        if vertical_gap <= 12 and overlap_ratio >= 0.6 and (line["y1"] - box["y0"]) <= 120:
            box["lines"].append(line["text"])
            box["x0"] = min(box["x0"], line["x0"])
            box["x1"] = max(box["x1"], line["x1"])
            box["y0"] = min(box["y0"], line["y0"])
            box["y1"] = max(box["y1"], line["y1"])
        else:
            boxes.append(box)
            box = {
                "lines": [line["text"]],
                "x0": line["x0"],
                "x1": line["x1"],
                "y0": line["y0"],
                "y1": line["y1"],
            }
    if box:
        boxes.append(box)

    # 3) –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –±–æ–∫—Å–æ–≤
    normalized = []
    seen = set()
    for b in boxes:
        text = " ".join(b["lines"]).strip()
        text = _normalize_text(text)
        if len(text) < 3:
            continue
        word_count = len([w for w in text.split(" ") if w])
        if word_count < 2 and len(text) < 10 and not text.isupper():
            continue
        if text in seen:
            continue
        seen.add(text)
        normalized.append({
            "text": text,
            "x0": b["x0"],
            "x1": b["x1"],
            "y0": b["y0"],
            "y1": b["y1"],
        })
    return normalized


def _split_line_segments(line_tokens: list[dict]) -> list[dict]:
    """–†–∞–∑–±–∏—Ç—å —Å—Ç—Ä–æ–∫—É –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã –ø–æ –±–æ–ª—å—à–∏–º —Ä–∞–∑—Ä—ã–≤–∞–º X."""
    if not line_tokens:
        return []
    segments = []
    current = [line_tokens[0]]
    gap_threshold = 28.0
    for prev, curr in zip(line_tokens, line_tokens[1:]):
        gap = curr["x0"] - prev["x1"]
        if gap > gap_threshold:
            segments.append(_line_segment(current))
            current = [curr]
        else:
            current.append(curr)
    if current:
        segments.append(_line_segment(current))
    return segments


def _line_segment(tokens: list[dict]) -> dict:
    """–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Å–µ–≥–º–µ–Ω—Ç –∏–∑ —Å–ø–∏—Å–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤."""
    text = " ".join(t["text"] for t in tokens).strip()
    return {
        "text": text,
        "x0": min(t["x0"] for t in tokens),
        "x1": max(t["x1"] for t in tokens),
        "y0": min(t["y0"] for t in tokens),
        "y1": max(t["y1"] for t in tokens),
    }


def _format_ocr_structure(ocr_markdown: str) -> str:
    """–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–∏–∞–≥—Ä–∞–º–º—ã –∏–∑ OCR."""
    boxes = _ocr_markdown_to_boxes(ocr_markdown)
    if not boxes:
        return ""
    
    def is_valid_box(text: str) -> bool:
        norm = _normalize_text(text)
        if len(norm) < 3:
            return False
        # –î–æ–ª—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
        cyr = len(re.findall(r'[–∞-—è–ê-–Ø—ë–Å]', norm))
        alpha = len(re.findall(r'[a-zA-Z–∞-—è–ê-–Ø—ë–Å]', norm))
        if alpha == 0 or (cyr / alpha) < 0.6:
            return False
        # –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –º—É—Å–æ—Ä–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        noise = len(re.findall(r'[^–∞-—è–ê-–Ø—ë–Åa-zA-Z0-9\\s.,:;()\\-]', norm))
        if noise / max(1, len(norm)) > 0.2:
            return False
        # –û–¥–∏–Ω–æ—á–Ω—ã–µ –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ (–∫—Ä–æ–º–µ –∫–ª—é—á–µ–≤—ã—Ö)
        words = [w for w in norm.split(" ") if w]
        if len(words) == 1 and len(norm) < 5 and norm.lower() not in {"–¥–∞", "–Ω–µ—Ç"}:
            return False
        return True
    
    filtered = [b for b in boxes if is_valid_box(b["text"])]
    if not filtered:
        return ""
    boxes = filtered
    max_y = max(b["y1"] for b in boxes)
    min_y = min(b["y0"] for b in boxes)
    height = max(1.0, max_y - min_y)
    split_y = min_y + height / 2
    has_two_lanes = height > 180 and len(boxes) >= 6

    def lane_label(b):
        if not has_two_lanes:
            return "lane"
        return "upper" if (b["y0"] + b["y1"]) / 2 <= split_y else "lower"

    lanes = {"upper": [], "lower": [], "lane": []}
    for b in boxes:
        lanes[lane_label(b)].append(b)

    lines = ["<!-- OCR –≥—Ä–∞—Ñ–∏–∫–∏ (—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ) -->", ""]
    lines.append("–≠–ª–µ–º–µ–Ω—Ç—ã:")
    for b in boxes:
        lines.append(f"- {b['text']}")
    lines.append("")

    if has_two_lanes:
        for lane_id, title in [("upper", "–î–æ—Ä–æ–∂–∫–∞ 1 (–≤–µ—Ä—Ö)"), ("lower", "–î–æ—Ä–æ–∂–∫–∞ 2 (–Ω–∏–∑)")]:
            lane_boxes = sorted(lanes[lane_id], key=lambda b: b["x0"])
            if lane_boxes:
                flow = " -> ".join(b["text"] for b in lane_boxes)
                lines.append(f"{title}:")
                lines.append(flow)
                lines.append("")
    else:
        lane_boxes = sorted(lanes["lane"], key=lambda b: b["x0"])
        if lane_boxes:
            flow = " -> ".join(b["text"] for b in lane_boxes)
            lines.append("–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å (OCR):")
            lines.append(flow)
            lines.append("")
    return "\n".join(lines)




def _interleave_text_and_tables(
    cleaned_lines: List[str],
    table_data_list: List[tuple],
    page,
    markdown_parts: List[str]
) -> None:
    """
    –ò–Ω—Ç–µ—Ä–ª–∏–≤–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ –∏ —Ç–∞–±–ª–∏—Ü –ø–æ Y-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º (–ö–∞—Ç–µ–≥–æ—Ä–∏—è 1).
    
    –í–º–µ—Å—Ç–æ "—Å–Ω–∞—á–∞–ª–∞ –≤–µ—Å—å —Ç–µ–∫—Å—Ç, –ø–æ—Ç–æ–º –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã" ‚Äî –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–∑–∏—Ü–∏–∏
    —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫ –∏ –≤—Å—Ç–∞–≤–ª—è–µ–º —Ç–∞–±–ª–∏—Ü—ã –º–µ–∂–¥—É –Ω–∏–º–∏ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö.
    
    Args:
        cleaned_lines: –û—á–∏—â–µ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
        table_data_list: –°–ø–∏—Å–æ–∫ (data, bbox_top) ‚Äî –¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã –∏ Y-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞ –≤–µ—Ä—Ö–∞
        page: pdfplumber page –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç —Å–ª–æ–≤
        markdown_parts: –í—ã—Ö–æ–¥–Ω–æ–π —Å–ø–∏—Å–æ–∫ –¥–ª—è append
    """
    if not table_data_list:
        for line in cleaned_lines:
            markdown_parts.append(_format_heading(line))
        return
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ç–∞–±–ª–∏—Ü—ã –ø–æ Y-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–µ (—Å–≤–µ—Ä—Ö—É –≤–Ω–∏–∑)
    sorted_tables = sorted(table_data_list, key=lambda t: t[1])
    
    # –ü–æ–ª—É—á–∞–µ–º Y-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Å—Ç—Ä–æ–∫ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ —Å–ª–æ–≤–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
    words = page.extract_words() or []
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–ª–æ–≤–∞ –ø–æ —Å—Ç—Ä–æ–∫–∞–º (–ø–æ top-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–µ)
    line_tops = {}
    for w in words:
        top = round(w.get("top", 0), 1)
        text_fragment = w.get("text", "").strip()
        if text_fragment:
            if top not in line_tops:
                line_tops[top] = []
            line_tops[top].append(text_fragment)
    
    # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º cleaned_lines —Å Y-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏
    # –°—Ç—Ä–∞—Ç–µ–≥–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ä—è–¥–æ–∫ —Å—Ç—Ä–æ–∫ ‚Äî –ø–µ—Ä–≤–∞—è cleaned_line —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ø–µ—Ä–≤–æ–π Y-–≥—Ä—É–ø–ø–µ –∏ —Ç.–¥.
    sorted_y_values = sorted(line_tops.keys())
    
    # –°–æ–∑–¥–∞—ë–º –º–∞–ø–ø–∏–Ω–≥: –¥–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–∫—Å—Ç–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏ ‚Äî –ø—Ä–∏–º–µ—Ä–Ω–∞—è Y-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞
    line_y_map = []  # [(line_text, approx_y)]
    y_idx = 0
    for line in cleaned_lines:
        line_norm = _normalize_text(line)
        if not line_norm:
            # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é Y + –Ω–µ–±–æ–ª—å—à–æ–π –æ—Ç—Å—Ç—É–ø
            prev_y = line_y_map[-1][1] if line_y_map else 0
            line_y_map.append((line, prev_y + 0.1))
            continue
        
        # –ò—â–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å—Ä–µ–¥–∏ Y-–≥—Ä—É–ø–ø
        matched = False
        for search_idx in range(y_idx, min(y_idx + 10, len(sorted_y_values))):
            y_val = sorted_y_values[search_idx]
            group_text = _normalize_text(" ".join(line_tops[y_val]))
            if line_norm[:20] in group_text or group_text[:20] in line_norm:
                line_y_map.append((line, y_val))
                y_idx = search_idx + 1
                matched = True
                break
        
        if not matched:
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª–µ–¥—É—é—â—É—é Y-–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—É
            if y_idx < len(sorted_y_values):
                line_y_map.append((line, sorted_y_values[y_idx]))
                y_idx += 1
            else:
                prev_y = line_y_map[-1][1] if line_y_map else 0
                line_y_map.append((line, prev_y + 0.1))
    
    # –¢–µ–ø–µ—Ä—å –≤—Å—Ç–∞–≤–ª—è–µ–º —Ç–∞–±–ª–∏—Ü—ã –º–µ–∂–¥—É —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏
    table_idx = 0
    for line_text, line_y in line_y_map:
        # –í—Å—Ç–∞–≤–ª—è–µ–º –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –î–û —ç—Ç–æ–π —Å—Ç—Ä–æ–∫–∏
        while table_idx < len(sorted_tables):
            tbl_data, tbl_top = sorted_tables[table_idx]
            if tbl_top <= line_y:
                markdown_parts.append(_table_to_markdown(tbl_data))
                table_idx += 1
            else:
                break
        markdown_parts.append(_format_heading(line_text))
    
    # –í—Å—Ç–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Ç–∞–±–ª–∏—Ü—ã –≤ –∫–æ–Ω–µ—Ü
    while table_idx < len(sorted_tables):
        tbl_data, _ = sorted_tables[table_idx]
        markdown_parts.append(_table_to_markdown(tbl_data))
        table_idx += 1


def _is_valid_table(data: List[List[str]]) -> bool:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è: —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∏–∑–≤–ª–µ—á—ë–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ä–µ–∞–ª—å–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ–π (–ö–∞—Ç–µ–≥–æ—Ä–∏—è 6).
    
    –û—Ç—Å–µ–∏–≤–∞–µ—Ç –ª–æ–∂–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã, —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤.
    """
    if not data:
        return False
    
    # –ú–∏–Ω–∏–º—É–º 2 —Å—Ç—Ä–æ–∫–∏ (–∑–∞–≥–æ–ª–æ–≤–æ–∫ + —Ö–æ—Ç—è –±—ã 1 —Å—Ç—Ä–æ–∫–∞ –¥–∞–Ω–Ω—ã—Ö)
    if len(data) < 2:
        return False
    
    # –ú–∏–Ω–∏–º—É–º 2 –∫–æ–ª–æ–Ω–∫–∏
    max_cols = max(len(row) for row in data)
    if max_cols < 2:
        return False
    
    # –ï—Å–ª–∏ > 80% –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≤ –æ–¥–Ω–æ–º —Å—Ç–æ–ª–±—Ü–µ ‚Äî —ç—Ç–æ —Å–∫–æ—Ä–µ–µ —Å–ø–∏—Å–æ–∫, –Ω–µ —Ç–∞–±–ª–∏—Ü–∞
    col_char_counts = [0] * max_cols
    total_chars = 0
    for row in data:
        for col_idx, cell in enumerate(row):
            cell_text = str(cell or '').strip()
            chars = len(cell_text)
            if col_idx < max_cols:
                col_char_counts[col_idx] += chars
            total_chars += chars
    
    if total_chars > 0:
        max_col_ratio = max(col_char_counts) / total_chars
        if max_col_ratio > 0.85:
            return False
    
    return True


def _forward_fill_table(data: List[List[str]]) -> List[List[str]]:
    """
    –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ None-—è—á–µ–µ–∫ –≤ —Ç–∞–±–ª–∏—Ü–µ (merged cells) –∑–Ω–∞—á–µ–Ω–∏–µ–º —Å–≤–µ—Ä—Ö—É (–ö–∞—Ç–µ–≥–æ—Ä–∏—è 2).
    
    pdfplumber –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –¥–ª—è —è—á–µ–µ–∫, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è —á–∞—Å—Ç—å—é
    –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–π —è—á–µ–π–∫–∏. –ó–∞–ø–æ–ª–Ω—è–µ–º –∏—Ö –∑–Ω–∞—á–µ–Ω–∏–µ–º –∏–∑ –±–ª–∏–∂–∞–π—à–µ–π –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ–π —è—á–µ–π–∫–∏ —Å–≤–µ—Ä—Ö—É.
    """
    if not data or len(data) < 2:
        return data
    
    max_cols = max(len(row) for row in data)
    result = []
    
    for row in data:
        # –î–æ–ø–æ–ª–Ω—è–µ–º —Å—Ç—Ä–æ–∫—É –¥–æ max_cols
        padded = list(row) + [None] * (max_cols - len(row))
        result.append(padded)
    
    # Forward fill –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º (—Å–≤–µ—Ä—Ö—É –≤–Ω–∏–∑)
    for col_idx in range(max_cols):
        last_value = None
        for row_idx in range(len(result)):
            cell = result[row_idx][col_idx]
            if cell is not None and str(cell).strip():
                last_value = cell
            elif last_value is not None and cell is None:
                # –ù–µ –∑–∞–ø–æ–ª–Ω—è–µ–º –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ (–∑–∞–≥–æ–ª–æ–≤–æ–∫) –µ—Å–ª–∏ –æ–Ω –ø—É—Å—Ç–æ–π
                if row_idx > 0:
                    result[row_idx][col_idx] = last_value
    
    return result


def _render_page_to_png(fitz_page, dpi: int = 200) -> Optional[bytes]:
    """–†–µ–Ω–¥–µ—Ä–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É PDF –≤ PNG –±–∞–π—Ç—ã –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ VLM."""
    try:
        import fitz as _fitz
        zoom = dpi / 72.0
        mat = _fitz.Matrix(zoom, zoom)
        pix = fitz_page.get_pixmap(matrix=mat)
        return pix.tobytes("png")
    except Exception:
        return None


def _process_image_ocr(
    image_data: bytes,
    page_num: int,
    bbox,
    qwen_service,
    ocr_client,
    figure_counter: int,
) -> Optional[str]:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/—Å—Ö–µ–º—ã —á–µ—Ä–µ–∑ VLM (Qwen 2B) –∏–ª–∏ DeepSeek OCR.
    
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
    1. Qwen 2B VLM (–ª–æ–∫–∞–ª—å–Ω—ã–π, –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å—Ö–µ–º)
    2. DeepSeek OCR (HTTP —Å–µ—Ä–≤–∏—Å, –±—ã—Å—Ç—Ä—ã–π –Ω–æ —Å–ª–∞–±–µ–µ –Ω–∞ —Å—Ö–µ–º–∞—Ö)
    3. Placeholder [–†–∏—Å—É–Ω–æ–∫ N, —Å—Ç—Ä. X]
    
    Returns:
        Markdown-–æ–ø–∏—Å–∞–Ω–∏–µ –∏–ª–∏ placeholder. None –µ—Å–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å.
    """
    # –í–∞—Ä–∏–∞–Ω—Ç 1: Qwen 2B VLM (–ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–π –¥–ª—è —Å—Ö–µ–º)
    if qwen_service is not None:
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–æ–º–ø—Ç –ø–æ —Ä–∞–∑–º–µ—Ä—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            from PIL import Image as PILImage
            import io as _io
            img = PILImage.open(_io.BytesIO(image_data))
            w, h = img.size
            aspect = w / max(h, 1)
            
            # –®–∏—Ä–æ–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—Ç–∞–±–ª–∏—Ü–∞) –∏–ª–∏ –∫–≤–∞–¥—Ä–∞—Ç–Ω–æ–µ (—Å—Ö–µ–º–∞)
            if aspect > 2.0:
                prompt = "table"
            else:
                prompt = (
                    "–û–ø–∏—à–∏ —ç—Ç—É —Å—Ö–µ–º—É/–¥–∏–∞–≥—Ä–∞–º–º—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. "
                    "–ï—Å–ª–∏ —ç—Ç–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ ‚Äî –æ–ø–∏—à–∏ –∏–µ—Ä–∞—Ä—Ö–∏—é –ø–æ–¥—á–∏–Ω–µ–Ω–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–ø–∏—Å–∫–∞. "
                    "–ï—Å–ª–∏ —ç—Ç–æ –±–ª–æ–∫-—Å—Ö–µ–º–∞ ‚Äî –æ–ø–∏—à–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —à–∞–≥–æ–≤ –∏ —É—Å–ª–æ–≤–∏—è. "
                    "–ë–µ—Ä–∏ —Ç–µ–∫—Å—Ç —Ç–æ—á–Ω–æ –∏–∑ –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫–æ–≤ –∏ –±–ª–æ–∫–æ–≤ –Ω–∞ —Å—Ö–µ–º–µ."
                )
            
            result = qwen_service.process_image(image_data, prompt)
            if result and len(result.strip()) > 10:
                return f"\n**–û–ø–∏—Å–∞–Ω–∏–µ —Å—Ö–µ–º—ã (—Å—Ç—Ä. {page_num}, Qwen VLM):**\n\n{result.strip()}\n"
        except Exception as e:
            print(f"Qwen VLM error (page {page_num}): {e}")
    
    # –í–∞—Ä–∏–∞–Ω—Ç 2: DeepSeek OCR (HTTP —Å–µ—Ä–≤–∏—Å)
    if ocr_client is not None:
        try:
            ocr_response = ocr_client.ocr_image(
                image_data=image_data,
                page_num=page_num,
                bbox=bbox,
                prompt_type="parse_figure",
                base_size=1280,
                image_size=1280
            )
            if ocr_response:
                structured = _format_ocr_structure(ocr_response.markdown)
                if structured:
                    return structured
        except RuntimeError as exc:
            print(f"OCR error (page {page_num}): {exc}")
    
    # –í–∞—Ä–∏–∞–Ω—Ç 3: Placeholder
    return f"\n[–†–∏—Å—É–Ω–æ–∫ {figure_counter}, —Å—Ç—Ä. {page_num}]\n"


def _detect_diagram_elements(
    diagram_detector,
    image_data: bytes,
    ocr_client,
    page_num: int,
    bbox
) -> Optional[str]:
    """
    –î–µ—Ç–µ–∫—Ü–∏—è —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–∏–∞–≥—Ä–∞–º–º—ã —á–µ—Ä–µ–∑ YOLO12 + OCR.
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç Markdown-–æ–ø–∏—Å–∞–Ω–∏–µ –¥–∏–∞–≥—Ä–∞–º–º—ã –∏–ª–∏ None –µ—Å–ª–∏ –¥–µ—Ç–µ–∫—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å.
    """
    try:
        # –ü–æ–ª—É—á–∞–µ–º OCR-–±–æ–∫—Å—ã –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        ocr_boxes = []
        try:
            ocr_response = ocr_client.ocr_image(
                image_data=image_data,
                page_num=page_num,
                bbox=bbox,
                prompt_type="parse_figure",
                base_size=1280,
                image_size=1280
            )
            if ocr_response and ocr_response.markdown:
                ocr_boxes = _ocr_markdown_to_boxes(ocr_response.markdown)
        except Exception:
            pass
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º YOLO12 –¥–µ—Ç–µ–∫—Ü–∏—é
        elements = diagram_detector.detect_and_merge_ocr(
            image=image_data,
            ocr_boxes=ocr_boxes,
            page_num=page_num,
            imgsz=640
        )
        
        if not elements or len(elements) < 2:
            return None
        
        # –°—Ç—Ä–æ–∏–º —Å–≤—è–∑–∏
        connections = diagram_detector.build_connections(elements)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Markdown
        md = diagram_detector.to_markdown(elements, connections)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º JSON (–∫–∞–∫ HTML-–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¥–ª—è –º–∞—à–∏–Ω–æ—á–∏—Ç–∞–µ–º–æ—Å—Ç–∏)
        import json
        diagram_json = diagram_detector.to_structured_json(elements, connections, page_num)
        json_comment = f"<!-- DIAGRAM_JSON: {json.dumps(diagram_json, ensure_ascii=False)} -->"
        
        return f"{json_comment}\n{md}"
    
    except Exception as e:
        print(f"Diagram detection error (page {page_num}): {e}")
        return None


def _bbox_overlaps_any(block_bbox, hf_bboxes, overlap_threshold=0.5) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –ø–µ—Ä–µ–∫—Ä—ã–≤–∞–µ—Ç—Å—è –ª–∏ bbox –±–ª–æ–∫–∞ —Å –ª—é–±—ã–º –∏–∑ –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–Ω—ã—Ö bbox.
    
    Args:
        block_bbox: bbox –±–ª–æ–∫–∞ (–æ–±—ä–µ–∫—Ç —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏ x0, y0, x1, y1)
        hf_bboxes: —Å–ø–∏—Å–æ–∫ bbox –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–æ–≤ –æ—Ç LayoutDetector (tuples: x0, y0, x1, y1)
        overlap_threshold: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–æ–ª—è –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è (0-1)
    
    Returns:
        True –µ—Å–ª–∏ –±–ª–æ–∫ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞–µ—Ç—Å—è —Å –∫–æ–ª–æ–Ω—Ç–∏—Ç—É–ª–æ–º
    """
    bx0, by0, bx1, by1 = block_bbox.x0, block_bbox.y0, block_bbox.x1, block_bbox.y1
    block_area = (bx1 - bx0) * (by1 - by0)
    if block_area <= 0:
        return False
    
    for hf_bbox in hf_bboxes:
        hx0, hy0, hx1, hy1 = hf_bbox
        # –í—ã—á–∏—Å–ª—è–µ–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
        ix0 = max(bx0, hx0)
        iy0 = max(by0, hy0)
        ix1 = min(bx1, hx1)
        iy1 = min(by1, hy1)
        
        if ix0 < ix1 and iy0 < iy1:
            intersection = (ix1 - ix0) * (iy1 - iy0)
            if intersection / block_area >= overlap_threshold:
                return True
    
    return False


def _char_in_bbox(char_obj: dict, bbox: tuple[float, float, float, float]) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ —Å–∏–º–≤–æ–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–Ω—É—Ç—Ä–∏ bbox —Ç–∞–±–ª–∏—Ü—ã."""
    x0, top, x1, bottom = bbox
    return (
        char_obj.get("x0", 0) >= x0
        and char_obj.get("x1", 0) <= x1
        and char_obj.get("top", 0) >= top
        and char_obj.get("bottom", 0) <= bottom
    )


def _filter_table_chars(page: pdfplumber.page.Page, tables: list) -> pdfplumber.page.Page:
    """–£–¥–∞–ª–∏—Ç—å —Å–∏–º–≤–æ–ª—ã, –ø–æ–ø–∞–¥–∞—é—â–∏–µ –≤ bbox —Ç–∞–±–ª–∏—Ü, —á—Ç–æ–±—ã —Ç–µ–∫—Å—Ç –Ω–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–ª—Å—è."""
    table_bboxes = [tbl.bbox for tbl in tables]

    def keep_obj(obj: dict) -> bool:
        if obj.get("object_type") != "char":
            return False
        for bbox in table_bboxes:
            if _char_in_bbox(obj, bbox):
                return False
        return True

    return page.filter(keep_obj)


def _table_to_markdown(table: List[List[str]]) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É –≤ Markdown."""
    if not table or not table[0]:
        return ''
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
    table = [row for row in table if any(cell for cell in row if cell)]
    if not table:
        return ''
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ª–æ–Ω–æ–∫
    max_cols = max(len(row) for row in table)
    table = [row + [''] * (max_cols - len(row)) for row in table]
    
    md_lines = ['\n']
    
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ç–∞–±–ª–∏—Ü—ã
    header = table[0]
    md_lines.append('| ' + ' | '.join(_escape_cell(cell) for cell in header) + ' |')
    md_lines.append('|' + '---|' * len(header))
    
    # –î–∞–Ω–Ω—ã–µ
    for row in table[1:]:
        md_lines.append('| ' + ' | '.join(_escape_cell(cell) for cell in row) + ' |')
    
    md_lines.append('\n')
    return '\n'.join(md_lines)


if __name__ == "__main__":
    # –¢–µ—Å—Ç
    import sys
    
    if len(sys.argv) > 1:
        pdf_path = sys.argv[1]
        text = extract_text_pdfplumber(pdf_path)
        print(text[:5000])
    else:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python pdfplumber_extractor.py <path_to_pdf>")
